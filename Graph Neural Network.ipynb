{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14285f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "from torch_geometric.nn import Linear\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df19a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_dir_old = r'C:\\Users\\yl646\\Documents\\ADHD_research\\DATA\\OUTPUT\\step_6_test\\MI_TABLE\\mi_adhd.npy'\n",
    "mi_dir_adhd   = r'C:\\Users\\yl646\\Documents\\ADHD_research\\DATA\\OUTPUT\\step_6_test_complete\\MI_TABLE\\mi_adhd.npy'\n",
    "mi_dir_control   = r'C:\\Users\\yl646\\Documents\\ADHD_research\\DATA\\OUTPUT\\step_6_test_complete\\MI_TABLE\\mi_control.npy'\n",
    "result_dir = r'C:\\Users\\yl646\\Documents\\ADHD_Research\\DATA\\OUTPUT\\step_6_test_complete\\RESULTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d96ffab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI table shape:  (2231, 20, 20) (epochs, channels, temp)\n",
      "MI table shape:  (1757, 20, 20) (epochs, channels, temp)\n",
      "# of graphs:  3988\n"
     ]
    }
   ],
   "source": [
    "ADHD_mi = np.load(mi_dir_adhd)\n",
    "CONTROL_mi = np.load(mi_dir_control)\n",
    "dataset_feat = []\n",
    "\n",
    "# ADHD MI table into pyG data format with features\n",
    "(epochs, channels, temp) = ADHD_mi.shape\n",
    "for epoch in range(epochs):\n",
    "    edges_np = np.array([[0],[0]])\n",
    "    for row in range(channels):\n",
    "        for col in range(channels):\n",
    "            edge = np.array([[row],[col]])\n",
    "            edges_np = np.concatenate((edges_np,edge),axis=1)\n",
    "            #weight = np.array([[ADHD_mi[epoch,row,col]]])\n",
    "            #weights_np = np.concatenate((weights_np, weight),axis=0)\n",
    "\n",
    "    edges_np = edges_np[:,1:]\n",
    "    edges = tensor(edges_np, dtype=torch.long)\n",
    "    y = torch.tensor([1], dtype=torch.int64)\n",
    "    x = torch.tensor(ADHD_mi[epoch,:,:], dtype=torch.float)\n",
    "    #x = x.flatten()[1:].view(channels-1, channels+1)[:,:-1].reshape(channels, channels-1)\n",
    "    \n",
    "    graph = Data(x=x, edge_index=edges, y=y)\n",
    "    dataset_feat.append(graph)\n",
    "    \n",
    "# CONTROL MI table into pyG data format with features\n",
    "(epochs, channels, temp) = CONTROL_mi.shape\n",
    "for epoch in range(epochs):\n",
    "    edges_np = np.array([[0],[0]])\n",
    "    for row in range(channels):\n",
    "        for col in range(channels):\n",
    "            edge = np.array([[row],[col]])\n",
    "            edges_np = np.concatenate((edges_np,edge),axis=1)\n",
    "            #weight = np.array([[CONTROL_mi[epoch,row,col]]])\n",
    "            #weights_np = np.concatenate((weights_np, weight),axis=0)\n",
    "        \n",
    "    edges_np = edges_np[:,1:]\n",
    "    edges = tensor(edges_np, dtype=torch.long)\n",
    "    y = torch.tensor([0], dtype=torch.int64)\n",
    "    x = torch.tensor(CONTROL_mi[epoch,:,:], dtype=torch.float)\n",
    "    #x = x.flatten()[1:].view(channels-1, channels+1)[:,:-1].reshape(channels, channels-1)\n",
    "    \n",
    "    graph = Data(x=x, edge_index=edges, y=y)\n",
    "    dataset_feat.append(graph)\n",
    "    \n",
    "print(\"MI table shape: \",ADHD_mi.shape, \"(epochs, channels, temp)\")\n",
    "print(\"MI table shape: \",CONTROL_mi.shape, \"(epochs, channels, temp)\")\n",
    "print(\"# of graphs: \",len(dataset_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ff7482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[20, 20], edge_index=[2, 400], y=[1])\n",
      "Number of nodes: 20\n",
      "Number of edges: 400\n",
      "Average node degree: 20.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Number of features: 20\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "data = dataset_feat[300]\n",
    "print(data)\n",
    "#print(f'Number of classes: {data.num_classes}')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Number of features: {data.num_node_features}')\n",
    "print(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0ae3995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batches\n",
      "128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 44 \n",
      "test batches\n",
      "128 128 128 104 "
     ]
    }
   ],
   "source": [
    "# shuffle data and split it into training and test set\n",
    "random.seed(1)\n",
    "random.shuffle(dataset_feat)\n",
    "train_dataset = dataset_feat[:3500]\n",
    "test_dataset = dataset_feat[3500:]\n",
    "\n",
    "# DataLoader returns a list of epochs\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(\"training batches\")\n",
    "for batch in train_loader:\n",
    "    print(batch.num_graphs, end =' ')\n",
    "print(\"\\ntest batches\")\n",
    "for batch in test_loader:\n",
    "    print(batch.num_graphs, end =' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2b45d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(SAGE, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = SAGEConv(data.num_node_features, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = SAGE(hidden_channels=20)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader, dataset):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch) \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd981a67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.6294, Test Acc: 0.6209\n",
      "Epoch: 002, Train Acc: 0.6914, Test Acc: 0.7029\n",
      "Epoch: 003, Train Acc: 0.7223, Test Acc: 0.7377\n",
      "Epoch: 004, Train Acc: 0.7677, Test Acc: 0.7725\n",
      "Epoch: 005, Train Acc: 0.8000, Test Acc: 0.7828\n",
      "Epoch: 006, Train Acc: 0.8089, Test Acc: 0.8012\n",
      "Epoch: 007, Train Acc: 0.8209, Test Acc: 0.8217\n",
      "Epoch: 008, Train Acc: 0.7891, Test Acc: 0.7643\n",
      "Epoch: 009, Train Acc: 0.8346, Test Acc: 0.8299\n",
      "Epoch: 010, Train Acc: 0.8554, Test Acc: 0.8402\n",
      "Epoch: 011, Train Acc: 0.8323, Test Acc: 0.8176\n",
      "Epoch: 012, Train Acc: 0.8757, Test Acc: 0.8668\n",
      "Epoch: 013, Train Acc: 0.8894, Test Acc: 0.8648\n",
      "Epoch: 014, Train Acc: 0.8860, Test Acc: 0.8525\n",
      "Epoch: 015, Train Acc: 0.8454, Test Acc: 0.8381\n",
      "Epoch: 016, Train Acc: 0.9009, Test Acc: 0.8689\n",
      "Epoch: 017, Train Acc: 0.8900, Test Acc: 0.8545\n",
      "Epoch: 018, Train Acc: 0.9031, Test Acc: 0.8750\n",
      "Epoch: 019, Train Acc: 0.8820, Test Acc: 0.8668\n",
      "Epoch: 020, Train Acc: 0.9094, Test Acc: 0.8811\n",
      "Epoch: 021, Train Acc: 0.8986, Test Acc: 0.8893\n",
      "Epoch: 022, Train Acc: 0.8949, Test Acc: 0.8770\n",
      "Epoch: 023, Train Acc: 0.9260, Test Acc: 0.8955\n",
      "Epoch: 024, Train Acc: 0.8860, Test Acc: 0.8504\n",
      "Epoch: 025, Train Acc: 0.9320, Test Acc: 0.9037\n",
      "Epoch: 026, Train Acc: 0.9331, Test Acc: 0.8975\n",
      "Epoch: 027, Train Acc: 0.9194, Test Acc: 0.8914\n",
      "Epoch: 028, Train Acc: 0.9289, Test Acc: 0.8996\n",
      "Epoch: 029, Train Acc: 0.9229, Test Acc: 0.8750\n",
      "Epoch: 030, Train Acc: 0.9389, Test Acc: 0.9016\n",
      "Epoch: 031, Train Acc: 0.9397, Test Acc: 0.9057\n",
      "Epoch: 032, Train Acc: 0.9323, Test Acc: 0.8955\n",
      "Epoch: 033, Train Acc: 0.9469, Test Acc: 0.9057\n",
      "Epoch: 034, Train Acc: 0.9380, Test Acc: 0.9098\n",
      "Epoch: 035, Train Acc: 0.9231, Test Acc: 0.8996\n",
      "Epoch: 036, Train Acc: 0.9263, Test Acc: 0.9078\n",
      "Epoch: 037, Train Acc: 0.9234, Test Acc: 0.8873\n",
      "Epoch: 038, Train Acc: 0.9063, Test Acc: 0.8770\n",
      "Epoch: 039, Train Acc: 0.9426, Test Acc: 0.9139\n",
      "Epoch: 040, Train Acc: 0.9394, Test Acc: 0.8975\n",
      "Epoch: 041, Train Acc: 0.9454, Test Acc: 0.9057\n",
      "Epoch: 042, Train Acc: 0.9503, Test Acc: 0.9201\n",
      "Epoch: 043, Train Acc: 0.9549, Test Acc: 0.9201\n",
      "Epoch: 044, Train Acc: 0.9460, Test Acc: 0.9139\n",
      "Epoch: 045, Train Acc: 0.9594, Test Acc: 0.9180\n",
      "Epoch: 046, Train Acc: 0.9037, Test Acc: 0.8730\n",
      "Epoch: 047, Train Acc: 0.9514, Test Acc: 0.9160\n",
      "Epoch: 048, Train Acc: 0.9600, Test Acc: 0.9221\n",
      "Epoch: 049, Train Acc: 0.9531, Test Acc: 0.9057\n",
      "Epoch: 050, Train Acc: 0.9563, Test Acc: 0.9139\n",
      "Epoch: 051, Train Acc: 0.9560, Test Acc: 0.9057\n",
      "Epoch: 052, Train Acc: 0.9474, Test Acc: 0.9139\n",
      "Epoch: 053, Train Acc: 0.9683, Test Acc: 0.9180\n",
      "Epoch: 054, Train Acc: 0.9589, Test Acc: 0.9283\n",
      "Epoch: 055, Train Acc: 0.9646, Test Acc: 0.9139\n",
      "Epoch: 056, Train Acc: 0.9663, Test Acc: 0.9201\n",
      "Epoch: 057, Train Acc: 0.9631, Test Acc: 0.9303\n",
      "Epoch: 058, Train Acc: 0.9606, Test Acc: 0.9242\n",
      "Epoch: 059, Train Acc: 0.9671, Test Acc: 0.9221\n",
      "Epoch: 060, Train Acc: 0.9531, Test Acc: 0.9262\n",
      "Epoch: 061, Train Acc: 0.9674, Test Acc: 0.9201\n",
      "Epoch: 062, Train Acc: 0.9709, Test Acc: 0.9242\n",
      "Epoch: 063, Train Acc: 0.9731, Test Acc: 0.9201\n",
      "Epoch: 064, Train Acc: 0.9729, Test Acc: 0.9119\n",
      "Epoch: 065, Train Acc: 0.9637, Test Acc: 0.9221\n",
      "Epoch: 066, Train Acc: 0.9577, Test Acc: 0.9180\n",
      "Epoch: 067, Train Acc: 0.9720, Test Acc: 0.9242\n",
      "Epoch: 068, Train Acc: 0.9731, Test Acc: 0.9160\n",
      "Epoch: 069, Train Acc: 0.9537, Test Acc: 0.9037\n",
      "Epoch: 070, Train Acc: 0.9751, Test Acc: 0.9160\n",
      "Epoch: 071, Train Acc: 0.9557, Test Acc: 0.9037\n",
      "Epoch: 072, Train Acc: 0.9751, Test Acc: 0.9139\n",
      "Epoch: 073, Train Acc: 0.9683, Test Acc: 0.9201\n",
      "Epoch: 074, Train Acc: 0.9737, Test Acc: 0.9201\n",
      "Epoch: 075, Train Acc: 0.9769, Test Acc: 0.9180\n",
      "Epoch: 076, Train Acc: 0.9549, Test Acc: 0.8996\n",
      "Epoch: 077, Train Acc: 0.9783, Test Acc: 0.9180\n",
      "Epoch: 078, Train Acc: 0.9709, Test Acc: 0.9180\n",
      "Epoch: 079, Train Acc: 0.9794, Test Acc: 0.9139\n",
      "Epoch: 080, Train Acc: 0.9663, Test Acc: 0.9221\n",
      "Epoch: 081, Train Acc: 0.9806, Test Acc: 0.9139\n",
      "Epoch: 082, Train Acc: 0.9806, Test Acc: 0.9242\n",
      "Epoch: 083, Train Acc: 0.9726, Test Acc: 0.9139\n",
      "Epoch: 084, Train Acc: 0.9714, Test Acc: 0.9119\n",
      "Epoch: 085, Train Acc: 0.9740, Test Acc: 0.9262\n",
      "Epoch: 086, Train Acc: 0.9723, Test Acc: 0.9201\n",
      "Epoch: 087, Train Acc: 0.9743, Test Acc: 0.9119\n",
      "Epoch: 088, Train Acc: 0.9697, Test Acc: 0.9160\n",
      "Epoch: 089, Train Acc: 0.9803, Test Acc: 0.9201\n",
      "Epoch: 090, Train Acc: 0.9706, Test Acc: 0.9242\n",
      "Epoch: 091, Train Acc: 0.9803, Test Acc: 0.9242\n",
      "Epoch: 092, Train Acc: 0.9503, Test Acc: 0.9139\n",
      "Epoch: 093, Train Acc: 0.9671, Test Acc: 0.9119\n",
      "Epoch: 094, Train Acc: 0.9723, Test Acc: 0.9160\n",
      "Epoch: 095, Train Acc: 0.9823, Test Acc: 0.9221\n",
      "Epoch: 096, Train Acc: 0.9740, Test Acc: 0.9303\n",
      "Epoch: 097, Train Acc: 0.9823, Test Acc: 0.9201\n",
      "Epoch: 098, Train Acc: 0.9746, Test Acc: 0.9201\n",
      "Epoch: 099, Train Acc: 0.9754, Test Acc: 0.9180\n",
      "Epoch: 100, Train Acc: 0.9791, Test Acc: 0.9221\n",
      "Epoch: 101, Train Acc: 0.9800, Test Acc: 0.9160\n",
      "Epoch: 102, Train Acc: 0.9829, Test Acc: 0.9283\n",
      "Epoch: 103, Train Acc: 0.9837, Test Acc: 0.9201\n",
      "Epoch: 104, Train Acc: 0.9717, Test Acc: 0.9180\n",
      "Epoch: 105, Train Acc: 0.9794, Test Acc: 0.9283\n",
      "Epoch: 106, Train Acc: 0.9869, Test Acc: 0.9262\n",
      "Epoch: 107, Train Acc: 0.9526, Test Acc: 0.8996\n",
      "Epoch: 108, Train Acc: 0.9766, Test Acc: 0.9180\n",
      "Epoch: 109, Train Acc: 0.9726, Test Acc: 0.9016\n",
      "Epoch: 110, Train Acc: 0.9746, Test Acc: 0.9139\n",
      "Epoch: 111, Train Acc: 0.9874, Test Acc: 0.9221\n",
      "Epoch: 112, Train Acc: 0.9791, Test Acc: 0.9242\n",
      "Epoch: 113, Train Acc: 0.9883, Test Acc: 0.9262\n",
      "Epoch: 114, Train Acc: 0.9809, Test Acc: 0.9303\n",
      "Epoch: 115, Train Acc: 0.9857, Test Acc: 0.9201\n",
      "Epoch: 116, Train Acc: 0.9794, Test Acc: 0.9303\n",
      "Epoch: 117, Train Acc: 0.9734, Test Acc: 0.9242\n",
      "Epoch: 118, Train Acc: 0.9634, Test Acc: 0.9057\n",
      "Epoch: 119, Train Acc: 0.9843, Test Acc: 0.9303\n",
      "Epoch: 120, Train Acc: 0.9831, Test Acc: 0.9262\n",
      "Epoch: 121, Train Acc: 0.9780, Test Acc: 0.9283\n",
      "Epoch: 122, Train Acc: 0.9717, Test Acc: 0.9201\n",
      "Epoch: 123, Train Acc: 0.9737, Test Acc: 0.9283\n",
      "Epoch: 124, Train Acc: 0.9866, Test Acc: 0.9221\n",
      "Epoch: 125, Train Acc: 0.9463, Test Acc: 0.8832\n",
      "Epoch: 126, Train Acc: 0.9880, Test Acc: 0.9262\n",
      "Epoch: 127, Train Acc: 0.9889, Test Acc: 0.9262\n",
      "Epoch: 128, Train Acc: 0.9834, Test Acc: 0.9180\n",
      "Epoch: 129, Train Acc: 0.9889, Test Acc: 0.9324\n",
      "Epoch: 130, Train Acc: 0.9823, Test Acc: 0.9201\n",
      "Epoch: 131, Train Acc: 0.9866, Test Acc: 0.9221\n",
      "Epoch: 132, Train Acc: 0.9694, Test Acc: 0.9037\n",
      "Epoch: 133, Train Acc: 0.9886, Test Acc: 0.9242\n",
      "Epoch: 134, Train Acc: 0.9860, Test Acc: 0.9180\n",
      "Epoch: 135, Train Acc: 0.9891, Test Acc: 0.9283\n",
      "Epoch: 136, Train Acc: 0.9791, Test Acc: 0.9078\n",
      "Epoch: 137, Train Acc: 0.9917, Test Acc: 0.9303\n",
      "Epoch: 138, Train Acc: 0.9917, Test Acc: 0.9303\n",
      "Epoch: 139, Train Acc: 0.9440, Test Acc: 0.8934\n",
      "Epoch: 140, Train Acc: 0.9860, Test Acc: 0.9303\n",
      "Epoch: 141, Train Acc: 0.9917, Test Acc: 0.9221\n",
      "Epoch: 142, Train Acc: 0.9829, Test Acc: 0.9221\n",
      "Epoch: 143, Train Acc: 0.9857, Test Acc: 0.9344\n",
      "Epoch: 144, Train Acc: 0.9589, Test Acc: 0.8934\n",
      "Epoch: 145, Train Acc: 0.9929, Test Acc: 0.9201\n",
      "Epoch: 146, Train Acc: 0.9886, Test Acc: 0.9201\n",
      "Epoch: 147, Train Acc: 0.9631, Test Acc: 0.9262\n",
      "Epoch: 148, Train Acc: 0.9943, Test Acc: 0.9283\n",
      "Epoch: 149, Train Acc: 0.9906, Test Acc: 0.9344\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 150):\n",
    "    train()\n",
    "    train_acc = test(train_loader,train_dataset)\n",
    "    test_acc = test(test_loader,test_dataset)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73b1bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIFF(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels,K):\n",
    "        super(DIFF, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = DCRNN(data.num_node_features, hidden_channels, K)\n",
    "        self.conv2 = DCRNN(hidden_channels, hidden_channels, K)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model_dcrnn = DIFF(hidden_channels=2, K=2)\n",
    "optimizer = torch.optim.Adam(model_dcrnn.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_dcrnn():\n",
    "    model_dcrnn.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model_dcrnn(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test_dcrnn(loader, dataset):\n",
    "    model_dcrnn.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model_dcrnn(data.x, data.edge_index, data.batch) \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88420c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.5609, Test Acc: 0.5492\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    train_dcrnn()\n",
    "    train_acc = test_dcrnn(train_loader,train_dataset)\n",
    "    test_acc = test_dcrnn(test_loader,test_dataset)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d538f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
