{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yongjun-l/ADHD-GNN/blob/master/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bc5eef3"
      },
      "source": [
        "# GNN, CNN Models with Cross Validation"
      ],
      "id": "5bc5eef3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqSTwN39ur6-"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0,nb_path)\n",
        "\n",
        "\n",
        "!pip install --upgrade pandas\n",
        "!pip install torch_scatter -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "!pip install torch_sparse -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "!pip install torch_geometric"
      ],
      "id": "vqSTwN39ur6-"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1f466a0c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import torch\n",
        "from torch import tensor, optim, nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, Linear, global_mean_pool\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader as CNNLoader\n",
        "from torch.nn.functional import normalize\n",
        "\n",
        "#from torch_geometric_temporal.nn.recurrent import DCRNN"
      ],
      "id": "1f466a0c"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f0eb25d5"
      },
      "outputs": [],
      "source": [
        "proj_dir  = '/content/drive/MyDrive/3_Research_Related/ADHD_Research_Google_Colab'\n",
        "\n",
        "# for GNN models with mutual information adj matrix\n",
        "mi_dir_adhd   = proj_dir + '/DATA/MI_TABLE/mi_adhd.npy'\n",
        "mi_dir_control   = proj_dir + '/DATA/MI_TABLE/mi_control.npy'\n",
        "\n",
        "# for GNN models with correlation adj matrix\n",
        "corr_dir_adhd   = proj_dir + '/DATA/CORR_TABLE/corr_adhd.npy'\n",
        "corr_dir_control   = proj_dir + '/DATA/CORR_TABLE/corr_control.npy'\n",
        "\n",
        "# for CNN model \n",
        "mi_dir_adhd_overlap = proj_dir + '/DATA/MI_TABLE/mi_adhd_overlap.npy'\n",
        "mi_dir_control_overlap = proj_dir + '/DATA/MI_TABLE/mi_control_overlap.npy'\n",
        "\n",
        "# save accuracy and trained models\n",
        "result_dir = proj_dir + '/DATA/RESULTS'\n",
        "model_dir = proj_dir + '/DATA/MODELS'\n",
        "\n",
        "epoch_adhd_dir = proj_dir + '/DATA/MI_TABLE/num_epoch_ADHD.npy'\n",
        "epoch_control_dir = proj_dir + '/DATA/MI_TABLE/num_epoch_CONTROL.npy'"
      ],
      "id": "f0eb25d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1b4ff27"
      },
      "source": [
        "### SAGE"
      ],
      "id": "a1b4ff27"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a2b45d89"
      },
      "outputs": [],
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, k_hop):\n",
        "        super(SAGE, self).__init__()\n",
        "        self.k_hop = k_hop\n",
        "        #torch.manual_seed(12345)\n",
        "        self.conv1 = SAGEConv(data.num_node_features, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, 2)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        for hop in range(self.k_hop):          \n",
        "            if hop==0:\n",
        "                x = self.conv1(x, edge_index)\n",
        "                x = x.relu()\n",
        "            \n",
        "            else:\n",
        "                x = self.conv2(x, edge_index)\n",
        "                x = x.relu()\n",
        "            \n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "        \n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        return x"
      ],
      "id": "a2b45d89"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c28182a"
      },
      "source": [
        "### GCN"
      ],
      "id": "8c28182a"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ffd8fb1"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, k_hop):\n",
        "        super(GCN, self).__init__()\n",
        "        self.k_hop = k_hop\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(data.num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, 2)\n",
        "        \n",
        "    def forward(self, x, edge_index, batch):\n",
        "        for hop in range(self.k_hop):          \n",
        "            if hop==0:\n",
        "                x = self.conv1(x, edge_index)\n",
        "                x = x.relu()\n",
        "            else:\n",
        "                x = self.conv2(x, edge_index)\n",
        "                x = x.relu()\n",
        "        \n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "        \n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        return x\n"
      ],
      "id": "1ffd8fb1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f44d4e0"
      },
      "source": [
        "### DIFF"
      ],
      "id": "5f44d4e0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "class DIFF(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels,K):\n",
        "        super(DIFF, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = DCRNN(data.num_node_features, hidden_channels, K)\n",
        "        self.conv2 = DCRNN(hidden_channels, hidden_channels, K)\n",
        "        self.lin = Linear(hidden_channels, 2)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        \n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x\n",
        "```"
      ],
      "metadata": {
        "id": "a2d34367"
      },
      "id": "a2d34367"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fcba0f4"
      },
      "source": [
        "### CNN"
      ],
      "id": "6fcba0f4"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c0e84b93"
      },
      "outputs": [],
      "source": [
        "def weight_init(m):\n",
        "    if type(m) == nn.Conv2d:\n",
        "        nn.init.normal_(m.weight)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, n_ch=4):\n",
        "        super(CNN, self).__init__()\n",
        "        self.n_ch = n_ch\n",
        "        \n",
        "        self.part_one = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=n_ch, out_channels=16, kernel_size=(3,3), padding=1),\n",
        "            nn.MaxPool2d(kernel_size=(3,3)),\n",
        "            nn.Dropout(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=1))\n",
        "        \n",
        "        self.part_two_a = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), padding=1))\n",
        "        \n",
        "        self.part_three_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding=1),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=1)\n",
        "        )\n",
        "        \n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=(3,3))\n",
        "        self.conv1 = nn.Conv2d(in_channels=128, out_channels=8, kernel_size=(3,3), padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=8, kernel_size=(3,3), padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=8, kernel_size=(3,3), padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=8, kernel_size=(3,3), padding=1)\n",
        "        \n",
        "        self.fc = nn.Linear(in_features=32, out_features=2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.bn = nn.BatchNorm2d(8)\n",
        "        \n",
        "        self.part_one.apply(weight_init)\n",
        "        self.part_two_a.apply(weight_init)\n",
        "        self.part_three_1.apply(weight_init)\n",
        "        nn.init.normal_(self.conv1.weight)\n",
        "        nn.init.normal_(self.conv2.weight)\n",
        "        nn.init.normal_(self.conv3.weight)\n",
        "        nn.init.normal_(self.conv4.weight)\n",
        "        nn.init.normal_(self.fc.weight)\n",
        "        \n",
        "    def part_three(self, x):\n",
        "        \n",
        "        x = self.part_three_1(x)\n",
        "        x1 = self.maxpool(x)\n",
        "        x1 = self.conv1(x1)\n",
        "        \n",
        "        x1 = self.bn(x1)\n",
        "        x1 = nn.functional.max_pool2d(input=x1, kernel_size=x1.shape[2:])\n",
        "        x1 = self.relu(x1)\n",
        "        \n",
        "        x2 = self.maxpool(x)\n",
        "        x2 = self.conv2(x2)\n",
        "        x2 = self.bn(x2)\n",
        "        x2 = nn.functional.avg_pool2d(input=x2, kernel_size=x2.shape[2:])\n",
        "        x2 = self.tanh(x2)\n",
        "        \n",
        "        x3 = self.maxpool(x)\n",
        "        x3 = self.conv3(x3)\n",
        "        x3 = self.bn(x3)\n",
        "        x3 = nn.functional.max_pool2d(input=x3, kernel_size=x3.shape[2:])\n",
        "        x3 = self.relu(x3)\n",
        "        \n",
        "        x4 = self.maxpool(x)\n",
        "        x4 = self.conv4(x4)\n",
        "        x4 = self.bn(x4)\n",
        "        x4 = nn.functional.avg_pool2d(input=x4, kernel_size=x4.shape[2:])\n",
        "        x4 = self.tanh(x4)\n",
        "        \n",
        "        x = torch.cat((x1,x2,x3,x4),1)\n",
        "        x = torch.squeeze(x)\n",
        "        return x\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.part_one(x)\n",
        "        x = self.part_two_a(x)\n",
        "        x = self.part_three(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "id": "c0e84b93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "097f9bab"
      },
      "source": [
        "## Create Dataset from MI tables"
      ],
      "id": "097f9bab"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "e34046f6"
      },
      "outputs": [],
      "source": [
        "def getGraph(mi_table, y):\n",
        "    \"\"\"\n",
        "    Input: Adjacency table with shape (epoch, channels, channels). dtype: np.array / y (label) value\n",
        "    output: List that contains pyG graph data objects for each MI table.\n",
        "    \"\"\"\n",
        "    dataset_graph=[]\n",
        "    (epochs, channels, channels) = mi_table.shape # Get number of epochs and channels\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        edges_np = np.array([[0],[0]]) # Initialize edges matrix\n",
        "        for row in range(channels):\n",
        "            for col in range(channels):\n",
        "                edge = np.array([[row],[col]]) # define fully connected edge matrix of shape (2x400)\n",
        "                edges_np = np.concatenate((edges_np,edge),axis=1)\n",
        "                \n",
        "                # our data is unweighted\n",
        "                #weight = np.array([[ADHD_mi[epoch,row,col]]])\n",
        "                #weights_np = np.concatenate((weights_np, weight),axis=0)\n",
        "\n",
        "        edges_np = edges_np[:,1:]\n",
        "        edges = tensor(edges_np, dtype=torch.long)\n",
        "        \n",
        "        # data types are required by the loss function\n",
        "        y = torch.tensor([y], dtype=torch.int64) \n",
        "        x = torch.tensor(mi_table[epoch,:,:], dtype=torch.float) # entire MI table is considered as graph data. \n",
        "\n",
        "        graph = Data(x=x, edge_index=edges, y=y) # Graph data stucture\n",
        "        dataset_graph.append(graph)\n",
        "    return dataset_graph"
      ],
      "id": "e34046f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71b3d654"
      },
      "source": [
        "### Graph - Training/Validation\n",
        "This dataset will be split into training set and validation set"
      ],
      "id": "71b3d654"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eba9b8df",
        "outputId": "caf922b3-0039-4d20-9806-abb5e2579647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MI table shape:  (2231, 20, 20) (epochs, channels, temp)\n",
            "MI table shape:  (1757, 20, 20) (epochs, channels, temp)\n",
            "# of graphs:  3988\n"
          ]
        }
      ],
      "source": [
        "#  Load mutual information matrices\n",
        "ADHD_mi = np.load(mi_dir_adhd)\n",
        "CONTROL_mi = np.load(mi_dir_control)\n",
        "\n",
        "ADHD_corr = np.load(corr_dir_adhd)\n",
        "CONTROL_corr = np.load(corr_dir_control)\n",
        "\n",
        "#  Construct graph from ADHD, CONTROL groups\n",
        "adhd_train_val_graph = getGraph(ADHD_mi, y=1)\n",
        "control_train_val_graph = getGraph(CONTROL_mi, y=0)\n",
        "\n",
        "adhd_train_val_graph_corr = getGraph(ADHD_corr, y=1)\n",
        "control_train_val_graph_corr = getGraph(CONTROL_corr, y=0)\n",
        "\n",
        "#  Combine and shuffle\n",
        "dataset_graph = adhd_train_val_graph + control_train_val_graph\n",
        "random.shuffle(dataset_graph)\n",
        "\n",
        "\n",
        "print(\"MI table shape: \",ADHD_mi.shape, \"(epochs, channels, temp)\")\n",
        "print(\"MI table shape: \",CONTROL_mi.shape, \"(epochs, channels, temp)\")\n",
        "print(\"# of graphs: \",len(dataset_graph))"
      ],
      "id": "eba9b8df"
    },
    {
      "cell_type": "code",
      "source": [
        "#  Get number of epochs for each patient.\n",
        "epo_per_adhd = np.load(epoch_adhd_dir)\n",
        "epo_per_control = np.load(epoch_control_dir)"
      ],
      "metadata": {
        "id": "bxV9eAteZ1-g"
      },
      "id": "bxV9eAteZ1-g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7008614a"
      },
      "source": [
        "### Graph - Test\n",
        "Test set is created by taking the average value of all mutual information tables for each patient."
      ],
      "id": "7008614a"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aabc2cab"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#  For each patient, find mean value of all MI tables\n",
        "#  Then create new test datapoint.\n",
        "adhd_test_mi = np.zeros((61,20,20))\n",
        "n=0\n",
        "for i, num_epo in enumerate(epo_per_adhd):\n",
        "    num_epo = int(num_epo)\n",
        "    adhd_test_mi[i, :, :]= np.mean(ADHD_mi[n:n+num_epo, : , : ])\n",
        "    n+=num_epo\n",
        "\n",
        "# same procedure for control group\n",
        "control_test_mi = np.zeros((60,20,20))\n",
        "n=0\n",
        "for i, num_epo in enumerate(epo_per_control):\n",
        "    num_epo = int(num_epo)\n",
        "    control_test_mi[i, :, :]= np.mean(CONTROL_mi[n:n+num_epo, : , : ])\n",
        "    n+=num_epo\n",
        "\n",
        "# getGraph function to turn this into a pyG graph data format    \n",
        "adhd_test_graph = getGraph(ADHD_mi, y=1)\n",
        "control_test_graph = getGraph(CONTROL_mi, y=0)\n",
        "\n",
        "test_graph = adhd_test_graph + control_test_graph\n",
        "# very important to shuffle. Unshuffled data does not learn. \n",
        "random.shuffle(test_graph)"
      ],
      "id": "aabc2cab"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3411c100"
      },
      "source": [
        "This is the summary of graph data objects."
      ],
      "id": "3411c100"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25effc2c",
        "outputId": "f5f729d7-7ddc-4590-ad24-ead951c70c29",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[20, 20], edge_index=[2, 400], y=[1])\n",
            "Number of nodes: 20\n",
            "Number of edges: 400\n",
            "Has isolated nodes: False\n",
            "Has self-loops: True\n",
            "Is undirected: True\n",
            "Number of features: 20\n"
          ]
        }
      ],
      "source": [
        "data = dataset_graph[300]\n",
        "print(data)\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')\n",
        "print(f'Number of features: {data.num_node_features}')"
      ],
      "id": "25effc2c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bc79797"
      },
      "source": [
        "### Image - Training/Validation"
      ],
      "id": "5bc79797"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f46c6475",
        "outputId": "69e925ec-03e0-4814-8c9a-7127360e3592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ADHD images 557\n",
            "Number of CONTROL images 439\n",
            "Total images 996\n",
            "Train-Validation Image Dataset Shape torch.Size([996, 4, 29, 29])\n"
          ]
        }
      ],
      "source": [
        "ADHD_mi_overlap = np.load(mi_dir_adhd_overlap)\n",
        "CONTROL_mi_overlap = np.load(mi_dir_control_overlap)\n",
        "\n",
        "n_ch = 4 # Motivated by R, G, B, Alpha channels\n",
        "(ADHD_epochs, channels, channels) = ADHD_mi_overlap.shape\n",
        "(CONTROL_epochs, channels, channels) = CONTROL_mi_overlap.shape\n",
        "\n",
        "#  Number of images\n",
        "num_img_ADHD = int(ADHD_epochs/n_ch)\n",
        "num_img_CONTROL = int(CONTROL_epochs/n_ch)\n",
        "n_img = num_img_ADHD+num_img_CONTROL\n",
        "\n",
        "#  Target dataset dimension\n",
        "img_data = np.zeros((n_img, n_ch, channels, channels))\n",
        "label = np.zeros(n_img)\n",
        "\n",
        "# select every 4 MI tables and assign it to img_data. This simply raises ADHD_mi_overlap's dimension by 1. \n",
        "for img in range(num_img_ADHD):\n",
        "    img_data[img, :, :, :] = ADHD_mi_overlap[n_ch*img:n_ch*(img+1), :, :]\n",
        "    label[img] = 1\n",
        "for img in range(num_img_CONTROL):\n",
        "    img_data[num_img_ADHD+img, :, :, :] = CONTROL_mi_overlap[n_ch*img : n_ch*(img+1), :, :]\n",
        "    label[num_img_ADHD+img] = 0\n",
        "\n",
        "# just like any other image dataset, all values are normalized to values between 0 and 1.\n",
        "for img in range(n_img):\n",
        "    for ch in range(n_ch):\n",
        "        img_data[img, ch, :, :] = (img_data[img, ch, :, :]) / (np.max(img_data[img, ch, :, :]))\n",
        "\n",
        "# TensorDataset class does not have in-built shuffle function. \n",
        "# list of integers upt to 995 is shuffled and used as an index to shuffle label and img_data.\n",
        "rand_idx = np.arange(996)\n",
        "random.shuffle(rand_idx)\n",
        "img_data = img_data[rand_idx, : , : , :]\n",
        "label = label[rand_idx]        \n",
        "\n",
        "img_data = torch.Tensor(img_data)\n",
        "label = torch.Tensor(label)\n",
        "label = label.long() # loss function requires this\n",
        "dataset_image = TensorDataset(img_data, label) #  Dataset class construction\n",
        "\n",
        "print('Number of ADHD images',num_img_ADHD)\n",
        "print('Number of CONTROL images',num_img_CONTROL)\n",
        "print('Total images',n_img)\n",
        "print('Train-Validation Image Dataset Shape',img_data.shape)"
      ],
      "id": "f46c6475"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62248efc"
      },
      "source": [
        "### Image Dataset - Test"
      ],
      "id": "62248efc"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7a4522dd"
      },
      "outputs": [],
      "source": [
        "epo_per_adhd = np.load(epoch_adhd_dir)\n",
        "epo_per_control = np.load(epoch_control_dir)\n",
        "\n",
        "adhd_test_img = np.zeros((61,4,29,29))\n",
        "control_test_img = np.zeros((60,4,29,29))\n",
        "test_label = np.zeros(121)\n",
        "\n",
        "# since image data is 3 dimensional, there were several ways to average image for patient. \n",
        "n=0\n",
        "for i, n_epo_patient in enumerate(epo_per_adhd):\n",
        "    n_im_patient = int(num_epo/n_ch)\n",
        "    im_patient = np.zeros((n_im_patient, 4, 29, 29))\n",
        "    for j in range(n_im_patient):\n",
        "        im_patient[j , : , : , :] = ADHD_mi_overlap[n+j*4 : n+(j+1)*4] # I found the images that would be in img_data.\n",
        "    adhd_test_img[i, :, :, :]= np.mean(im_patient, axis=0) # then averaged the images element-wise.\n",
        "    test_label[i]=1\n",
        "    n+=num_epo\n",
        "\n",
        "n=0\n",
        "for i, n_epo_patient in enumerate(epo_per_control):\n",
        "    n_im_patient = int(num_epo/n_ch)\n",
        "    im_patient = np.zeros((n_im_patient, 4, 29, 29))\n",
        "    for j in range(n_im_patient):\n",
        "        im_patient[j , : , : , :] = CONTROL_mi_overlap[n+j*4 : n+(j+1)*4]\n",
        "    control_test_img[i, :, :, :]= np.mean(im_patient, axis=0)\n",
        "    n+=num_epo\n",
        "\n",
        "test_img = np.concatenate((adhd_test_img, control_test_img), axis = 0)\n",
        "\n",
        "# test set is shuffled in the same manner\n",
        "rand_idx = np.arange(121)\n",
        "random.shuffle(rand_idx)\n",
        "test_img = test_img[rand_idx, : , : , :]\n",
        "test_label = test_label[rand_idx]\n",
        "\n",
        "test_img = torch.Tensor(test_img)\n",
        "test_label = torch.Tensor(test_label)\n",
        "test_label = test_label.long()\n",
        "test_dataset_img = TensorDataset(test_img, test_label)"
      ],
      "id": "7a4522dd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfc243ff"
      },
      "source": [
        "## Main Model Training and Testing with K-fold"
      ],
      "id": "bfc243ff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa8f135c"
      },
      "source": [
        "### Train / Test Functions"
      ],
      "id": "aa8f135c"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0fef5616"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, loss_fn, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    for data in loader:  # Iterate batches\n",
        "        out = model(data.x, data.edge_index, data.batch)  # forward pass\n",
        "        loss = loss_fn(out, data.y) # loss\n",
        "        loss.backward()  # gradient\n",
        "        optimizer.step()  # update weights\n",
        "        optimizer.zero_grad()  # clear gradients\n",
        "    return\n",
        "\n",
        "def test(model, loader, dataset):    \n",
        "    correct = 0\n",
        "    for data in loader:  \n",
        "        out = model(data.x, data.edge_index, data.batch) \n",
        "        pred = out.argmax(dim=1)  # make prediction based on returned softmax values\n",
        "        correct += int((pred == data.y).sum()) # count correct predictions\n",
        "    return correct / len(dataset)\n",
        "\n",
        "# since CNN model does not have data object like GNN, train and test functions were implemented separately.\n",
        "def train_cnn(model, loader, loss_fn, optimizer):\n",
        "    correct=0\n",
        "    for i, data in enumerate(loader):\n",
        "        inputs, labels = data\n",
        "        if inputs.shape[0] ==1:  # k-fold would randomly return a fold size that would result in 1 mod batch_size. This was causing dimention error. \n",
        "            return\n",
        "        pred = model(inputs)\n",
        "        loss = loss_fn(pred, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred_argmax = pred.argmax(dim=1) \n",
        "        correct += int((pred_argmax == labels).sum())\n",
        "        \n",
        "def test_cnn(model, loader, dataset):  \n",
        "    correct = 0\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(loader): \n",
        "        inputs, labels = data\n",
        "        if inputs.shape[0] ==1:\n",
        "            break\n",
        "        pred = model(inputs)\n",
        "        pred_argmax = pred.argmax(dim=1)  \n",
        "        correct += int((pred_argmax == labels).sum())\n",
        "        \n",
        "    return correct / len(dataset) "
      ],
      "id": "0fef5616"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ac0c1fd"
      },
      "source": [
        "### Main Function"
      ],
      "id": "1ac0c1fd"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9c20f9b8"
      },
      "outputs": [],
      "source": [
        "def main(model_name, dataset, test_dataset, model_dir, result_dir, k_hop=1, k_fold=10, n_epo=150, h_ch = 20, lr=0.0001, save=True):\n",
        "    start = time.time()\n",
        "    \n",
        "    \n",
        "    # Implement k-fold cross validation\n",
        "    kf = KFold(n_splits=k_fold, shuffle=True)\n",
        "    \n",
        "    # For each fold\n",
        "    for fold, (train_index, valid_index) in enumerate(kf.split(dataset)):\n",
        "\n",
        "        # Define model, optimizer, and loss function\n",
        "        if model_name == 'SAGE':\n",
        "            model = SAGE(hidden_channels=h_ch, k_hop=k_hop)\n",
        "        elif model_name == 'GCN':\n",
        "            model = GCN(hidden_channels=h_ch, k_hop=k_hop)\n",
        "        #elif model_name == 'DIFF':\n",
        "        #    model = DIFF(hidden_channels=h_ch, K=k_hop)\n",
        "        elif model_name =='CNN':\n",
        "            model = CNN()\n",
        "        else:\n",
        "            print('Error: model not defined')\n",
        "            return\n",
        "        \n",
        "        #opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "        opt = optim.NAdam(model.parameters(), lr=lr, betas = (0.9,0.999), momentum_decay=0.004)\n",
        "        loss_fnc = torch.nn.CrossEntropyLoss()\n",
        "        \n",
        "        list_train_acc = []\n",
        "        list_valid_acc = []\n",
        "        list_test_acc = []\n",
        "        \n",
        "        # Split train, test set and define dataloader\n",
        "        train_dataset = [dataset[i] for i in train_index]\n",
        "        valid_dataset = [dataset[i] for i in valid_index]\n",
        "        \n",
        "        if model_name =='CNN':\n",
        "            train_loader = CNNLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "            valid_loader = CNNLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "            test_loader = CNNLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "        else:\n",
        "            train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
        "            valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
        "            test_loader = DataLoader(test_dataset, batch_size=121, shuffle=False)  # whole set\n",
        "        \n",
        "        # For each epoch\n",
        "        for epoch in range(n_epo):\n",
        "            if model_name == 'CNN':\n",
        "                train_cnn(model, train_loader, loss_fnc, opt)\n",
        "            else:\n",
        "                train(model, train_loader, loss_fnc, opt)\n",
        "\n",
        "            # Get accuracy for train and validation set\n",
        "            if model_name =='CNN':\n",
        "                train_acc = test_cnn(model, train_loader, train_dataset)\n",
        "                valid_acc = test_cnn(model, valid_loader, valid_dataset)\n",
        "                test_acc = test_cnn(model, test_loader, test_dataset)\n",
        "            else:\n",
        "                train_acc = test(model, train_loader, train_dataset)\n",
        "                valid_acc = test(model, valid_loader, valid_dataset)\n",
        "                test_acc = test(model, test_loader, test_dataset)\n",
        "\n",
        "            list_train_acc.append(train_acc)\n",
        "            list_valid_acc.append(valid_acc)\n",
        "            list_test_acc.append(test_acc)\n",
        "            \n",
        "            #if epoch+1 % 1 ==0:\n",
        "            print(f'Fold: {fold+1}, Epoch: {epoch+1:03d}, Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, Test: {test_acc:.4f}')\n",
        "    \n",
        "    ####################################\n",
        "    # Save the results for visualization and analysis\n",
        "    ####################################\n",
        "    if save==False:\n",
        "      return\n",
        "      \n",
        "    # Turn accuracy to numpy array\n",
        "    list_train_acc = np.array(list_train_acc)\n",
        "    list_valid_acc = np.array(list_valid_acc)\n",
        "    list_test_acc = np.array(list_test_acc)\n",
        "\n",
        "    # Reshape results as column vector\n",
        "    list_train_acc = np.reshape(list_train_acc, (-1,1))\n",
        "    list_valid_acc = np.reshape(list_valid_acc, (-1,1))\n",
        "    list_test_acc = np.reshape(list_test_acc, (-1,1))\n",
        "    results = np.concatenate((list_train_acc,list_valid_acc,list_test_acc), axis=1)\n",
        "    results = pd.DataFrame(results, columns=['Train', 'Valid', 'Test'])\n",
        "    \n",
        "    # Save accuracy log\n",
        "    filename = result_dir+'/kfold_'\n",
        "    if model_name == 'CNN':\n",
        "        filename += f'{model_name}_ndam_epo_{n_epo}.csv'\n",
        "    else:\n",
        "        filename += f'{model_name}_k_{k_hop}_ndam_epo_{n_epo}_lr_{lr}.csv'\n",
        "    results.to_csv(filename, float_format='%.3f', index=False, header=True)\n",
        "\n",
        "    # Save model for later use\n",
        "    filename_model = model_dir+'/kfold_'\n",
        "    if model_name == 'CNN':\n",
        "        filename_model += f'{model_name}.pth'\n",
        "    else: \n",
        "        filename_model += f'{model_name}_k_{k_hop}.pth'\n",
        "    torch.save(model, filename_model)\n",
        "\n",
        "    # Retain saved model\n",
        "    # This may not work for other environments due to different path names\n",
        "    model1 = torch.load(filename_model)\n",
        "    #test_acc = test(model1, test_loader, test_dataset)\n",
        "    #print(f'Acc: {test_acc:.4f}')\n",
        "    print('\\nElapsed Time: ',time.time()-start)"
      ],
      "id": "9c20f9b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29bae8fa"
      },
      "source": [
        "## CNN Training"
      ],
      "id": "29bae8fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a25743f0"
      },
      "source": [
        "## SAGE Training with k = 1, 2, 3, 4"
      ],
      "id": "a25743f0"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db851743",
        "outputId": "a60043cd-b171-4e6f-f32a-825aecdbd66a",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4341, Valid: 0.4937, Test: 0.4396\n",
            "Fold: 1, Epoch: 002, Train: 0.4347, Valid: 0.4837, Test: 0.4398\n",
            "Fold: 1, Epoch: 003, Train: 0.4327, Valid: 0.4862, Test: 0.4406\n",
            "Fold: 1, Epoch: 004, Train: 0.4324, Valid: 0.4837, Test: 0.4378\n",
            "Fold: 1, Epoch: 005, Train: 0.4372, Valid: 0.4887, Test: 0.4441\n",
            "Fold: 1, Epoch: 006, Train: 0.4347, Valid: 0.4987, Test: 0.4418\n",
            "Fold: 1, Epoch: 007, Train: 0.4427, Valid: 0.5038, Test: 0.4453\n",
            "Fold: 1, Epoch: 008, Train: 0.4489, Valid: 0.4912, Test: 0.4526\n",
            "Fold: 1, Epoch: 009, Train: 0.4533, Valid: 0.4837, Test: 0.4534\n",
            "Fold: 1, Epoch: 010, Train: 0.4567, Valid: 0.5113, Test: 0.4677\n",
            "Fold: 1, Epoch: 011, Train: 0.4815, Valid: 0.5188, Test: 0.4727\n",
            "Fold: 1, Epoch: 012, Train: 0.4759, Valid: 0.5138, Test: 0.4809\n",
            "Fold: 1, Epoch: 013, Train: 0.4862, Valid: 0.5163, Test: 0.4880\n",
            "Fold: 1, Epoch: 014, Train: 0.5015, Valid: 0.5188, Test: 0.4935\n",
            "Fold: 1, Epoch: 015, Train: 0.4909, Valid: 0.5063, Test: 0.5118\n",
            "Fold: 1, Epoch: 016, Train: 0.5118, Valid: 0.5063, Test: 0.5150\n",
            "Fold: 1, Epoch: 017, Train: 0.5183, Valid: 0.5363, Test: 0.5075\n",
            "Fold: 1, Epoch: 018, Train: 0.5372, Valid: 0.5363, Test: 0.5261\n",
            "Fold: 1, Epoch: 019, Train: 0.5347, Valid: 0.5363, Test: 0.5211\n",
            "Fold: 1, Epoch: 020, Train: 0.5219, Valid: 0.5664, Test: 0.5416\n",
            "Fold: 1, Epoch: 021, Train: 0.5339, Valid: 0.4912, Test: 0.5263\n",
            "Fold: 1, Epoch: 022, Train: 0.5160, Valid: 0.5614, Test: 0.5318\n",
            "Fold: 1, Epoch: 023, Train: 0.5333, Valid: 0.5263, Test: 0.5344\n",
            "Fold: 1, Epoch: 024, Train: 0.5492, Valid: 0.5088, Test: 0.5374\n",
            "Fold: 1, Epoch: 025, Train: 0.5481, Valid: 0.5414, Test: 0.5434\n",
            "Fold: 1, Epoch: 026, Train: 0.5442, Valid: 0.5313, Test: 0.5469\n",
            "Fold: 1, Epoch: 027, Train: 0.5539, Valid: 0.5639, Test: 0.5469\n",
            "Fold: 1, Epoch: 028, Train: 0.5481, Valid: 0.5388, Test: 0.5594\n",
            "Fold: 1, Epoch: 029, Train: 0.5400, Valid: 0.5113, Test: 0.5700\n",
            "Fold: 1, Epoch: 030, Train: 0.5453, Valid: 0.5188, Test: 0.5424\n",
            "Fold: 1, Epoch: 031, Train: 0.5567, Valid: 0.5213, Test: 0.5567\n",
            "Fold: 1, Epoch: 032, Train: 0.5690, Valid: 0.5363, Test: 0.5579\n",
            "Fold: 1, Epoch: 033, Train: 0.5678, Valid: 0.4987, Test: 0.5685\n",
            "Fold: 1, Epoch: 034, Train: 0.5704, Valid: 0.5063, Test: 0.5514\n",
            "Fold: 1, Epoch: 035, Train: 0.5653, Valid: 0.5414, Test: 0.5707\n",
            "Fold: 1, Epoch: 036, Train: 0.5684, Valid: 0.5489, Test: 0.5582\n",
            "Fold: 1, Epoch: 037, Train: 0.5795, Valid: 0.5038, Test: 0.5659\n",
            "Fold: 1, Epoch: 038, Train: 0.5684, Valid: 0.5338, Test: 0.5782\n",
            "Fold: 1, Epoch: 039, Train: 0.5823, Valid: 0.5439, Test: 0.5750\n",
            "Fold: 1, Epoch: 040, Train: 0.5809, Valid: 0.5163, Test: 0.5760\n",
            "Fold: 1, Epoch: 041, Train: 0.5770, Valid: 0.4987, Test: 0.5700\n",
            "Fold: 1, Epoch: 042, Train: 0.5779, Valid: 0.5163, Test: 0.5617\n",
            "Fold: 1, Epoch: 043, Train: 0.5754, Valid: 0.5338, Test: 0.5747\n",
            "Fold: 1, Epoch: 044, Train: 0.5843, Valid: 0.5489, Test: 0.5740\n",
            "Fold: 1, Epoch: 045, Train: 0.5868, Valid: 0.5664, Test: 0.5805\n",
            "Fold: 1, Epoch: 046, Train: 0.5837, Valid: 0.5489, Test: 0.5752\n",
            "Fold: 1, Epoch: 047, Train: 0.5821, Valid: 0.5213, Test: 0.5810\n",
            "Fold: 1, Epoch: 048, Train: 0.5901, Valid: 0.5113, Test: 0.5787\n",
            "Fold: 1, Epoch: 049, Train: 0.5834, Valid: 0.5163, Test: 0.5722\n",
            "Fold: 1, Epoch: 050, Train: 0.5893, Valid: 0.5313, Test: 0.5807\n",
            "Fold: 2, Epoch: 001, Train: 0.4798, Valid: 0.4912, Test: 0.4829\n",
            "Fold: 2, Epoch: 002, Train: 0.4712, Valid: 0.4762, Test: 0.4940\n",
            "Fold: 2, Epoch: 003, Train: 0.4929, Valid: 0.4762, Test: 0.5118\n",
            "Fold: 2, Epoch: 004, Train: 0.4926, Valid: 0.5138, Test: 0.5000\n",
            "Fold: 2, Epoch: 005, Train: 0.5174, Valid: 0.5038, Test: 0.5158\n",
            "Fold: 2, Epoch: 006, Train: 0.5060, Valid: 0.4912, Test: 0.5113\n",
            "Fold: 2, Epoch: 007, Train: 0.5194, Valid: 0.5388, Test: 0.5206\n",
            "Fold: 2, Epoch: 008, Train: 0.5183, Valid: 0.4812, Test: 0.5243\n",
            "Fold: 2, Epoch: 009, Train: 0.5191, Valid: 0.5414, Test: 0.5406\n",
            "Fold: 2, Epoch: 010, Train: 0.5336, Valid: 0.5063, Test: 0.5293\n",
            "Fold: 2, Epoch: 011, Train: 0.5389, Valid: 0.5013, Test: 0.5218\n",
            "Fold: 2, Epoch: 012, Train: 0.5447, Valid: 0.5464, Test: 0.5298\n",
            "Fold: 2, Epoch: 013, Train: 0.5383, Valid: 0.5363, Test: 0.5346\n",
            "Fold: 2, Epoch: 014, Train: 0.5550, Valid: 0.5589, Test: 0.5434\n",
            "Fold: 2, Epoch: 015, Train: 0.5378, Valid: 0.5689, Test: 0.5371\n",
            "Fold: 2, Epoch: 016, Train: 0.5430, Valid: 0.5489, Test: 0.5489\n",
            "Fold: 2, Epoch: 017, Train: 0.5464, Valid: 0.5414, Test: 0.5537\n",
            "Fold: 2, Epoch: 018, Train: 0.5503, Valid: 0.5414, Test: 0.5466\n",
            "Fold: 2, Epoch: 019, Train: 0.5534, Valid: 0.5363, Test: 0.5504\n",
            "Fold: 2, Epoch: 020, Train: 0.5589, Valid: 0.5388, Test: 0.5489\n",
            "Fold: 2, Epoch: 021, Train: 0.5472, Valid: 0.5288, Test: 0.5627\n",
            "Fold: 2, Epoch: 022, Train: 0.5690, Valid: 0.5439, Test: 0.5532\n",
            "Fold: 2, Epoch: 023, Train: 0.5573, Valid: 0.5614, Test: 0.5722\n",
            "Fold: 2, Epoch: 024, Train: 0.5637, Valid: 0.5514, Test: 0.5735\n",
            "Fold: 2, Epoch: 025, Train: 0.5698, Valid: 0.5564, Test: 0.5725\n",
            "Fold: 2, Epoch: 026, Train: 0.5756, Valid: 0.5464, Test: 0.5737\n",
            "Fold: 2, Epoch: 027, Train: 0.5701, Valid: 0.5388, Test: 0.5742\n",
            "Fold: 2, Epoch: 028, Train: 0.5784, Valid: 0.5639, Test: 0.5762\n",
            "Fold: 2, Epoch: 029, Train: 0.5729, Valid: 0.5614, Test: 0.5747\n",
            "Fold: 2, Epoch: 030, Train: 0.5823, Valid: 0.5514, Test: 0.5735\n",
            "Fold: 2, Epoch: 031, Train: 0.5770, Valid: 0.5739, Test: 0.5745\n",
            "Fold: 2, Epoch: 032, Train: 0.5851, Valid: 0.5514, Test: 0.5715\n",
            "Fold: 2, Epoch: 033, Train: 0.5823, Valid: 0.5564, Test: 0.5795\n",
            "Fold: 2, Epoch: 034, Train: 0.5818, Valid: 0.5764, Test: 0.5825\n",
            "Fold: 2, Epoch: 035, Train: 0.5907, Valid: 0.5689, Test: 0.5868\n",
            "Fold: 2, Epoch: 036, Train: 0.5784, Valid: 0.5714, Test: 0.5830\n",
            "Fold: 2, Epoch: 037, Train: 0.5729, Valid: 0.5489, Test: 0.5832\n",
            "Fold: 2, Epoch: 038, Train: 0.5821, Valid: 0.5564, Test: 0.5875\n",
            "Fold: 2, Epoch: 039, Train: 0.5871, Valid: 0.5564, Test: 0.5770\n",
            "Fold: 2, Epoch: 040, Train: 0.5921, Valid: 0.5639, Test: 0.5812\n",
            "Fold: 2, Epoch: 041, Train: 0.5843, Valid: 0.5739, Test: 0.5875\n",
            "Fold: 2, Epoch: 042, Train: 0.5885, Valid: 0.5614, Test: 0.5908\n",
            "Fold: 2, Epoch: 043, Train: 0.5943, Valid: 0.5890, Test: 0.5825\n",
            "Fold: 2, Epoch: 044, Train: 0.5907, Valid: 0.5739, Test: 0.5935\n",
            "Fold: 2, Epoch: 045, Train: 0.6018, Valid: 0.5639, Test: 0.5835\n",
            "Fold: 2, Epoch: 046, Train: 0.5893, Valid: 0.5689, Test: 0.5805\n",
            "Fold: 2, Epoch: 047, Train: 0.5968, Valid: 0.5714, Test: 0.5933\n",
            "Fold: 2, Epoch: 048, Train: 0.5801, Valid: 0.5714, Test: 0.5900\n",
            "Fold: 2, Epoch: 049, Train: 0.5954, Valid: 0.5639, Test: 0.5863\n",
            "Fold: 2, Epoch: 050, Train: 0.6007, Valid: 0.5739, Test: 0.5938\n",
            "Fold: 3, Epoch: 001, Train: 0.4926, Valid: 0.4762, Test: 0.4812\n",
            "Fold: 3, Epoch: 002, Train: 0.5074, Valid: 0.4612, Test: 0.5008\n",
            "Fold: 3, Epoch: 003, Train: 0.5107, Valid: 0.4737, Test: 0.4975\n",
            "Fold: 3, Epoch: 004, Train: 0.5026, Valid: 0.5088, Test: 0.5130\n",
            "Fold: 3, Epoch: 005, Train: 0.5185, Valid: 0.5038, Test: 0.5098\n",
            "Fold: 3, Epoch: 006, Train: 0.4940, Valid: 0.5113, Test: 0.5038\n",
            "Fold: 3, Epoch: 007, Train: 0.5169, Valid: 0.5088, Test: 0.5208\n",
            "Fold: 3, Epoch: 008, Train: 0.5163, Valid: 0.5188, Test: 0.5213\n",
            "Fold: 3, Epoch: 009, Train: 0.5274, Valid: 0.5639, Test: 0.5248\n",
            "Fold: 3, Epoch: 010, Train: 0.5224, Valid: 0.5288, Test: 0.5306\n",
            "Fold: 3, Epoch: 011, Train: 0.5255, Valid: 0.5338, Test: 0.5286\n",
            "Fold: 3, Epoch: 012, Train: 0.5400, Valid: 0.5539, Test: 0.5404\n",
            "Fold: 3, Epoch: 013, Train: 0.5500, Valid: 0.5514, Test: 0.5474\n",
            "Fold: 3, Epoch: 014, Train: 0.5545, Valid: 0.5990, Test: 0.5441\n",
            "Fold: 3, Epoch: 015, Train: 0.5489, Valid: 0.5815, Test: 0.5549\n",
            "Fold: 3, Epoch: 016, Train: 0.5539, Valid: 0.5965, Test: 0.5549\n",
            "Fold: 3, Epoch: 017, Train: 0.5676, Valid: 0.5815, Test: 0.5637\n",
            "Fold: 3, Epoch: 018, Train: 0.5578, Valid: 0.5714, Test: 0.5654\n",
            "Fold: 3, Epoch: 019, Train: 0.5709, Valid: 0.5714, Test: 0.5735\n",
            "Fold: 3, Epoch: 020, Train: 0.5676, Valid: 0.6015, Test: 0.5692\n",
            "Fold: 3, Epoch: 021, Train: 0.5614, Valid: 0.5840, Test: 0.5690\n",
            "Fold: 3, Epoch: 022, Train: 0.5645, Valid: 0.6291, Test: 0.5705\n",
            "Fold: 3, Epoch: 023, Train: 0.5762, Valid: 0.6140, Test: 0.5574\n",
            "Fold: 3, Epoch: 024, Train: 0.5737, Valid: 0.5865, Test: 0.5594\n",
            "Fold: 3, Epoch: 025, Train: 0.5731, Valid: 0.5940, Test: 0.5802\n",
            "Fold: 3, Epoch: 026, Train: 0.5690, Valid: 0.5915, Test: 0.5797\n",
            "Fold: 3, Epoch: 027, Train: 0.5768, Valid: 0.5990, Test: 0.5780\n",
            "Fold: 3, Epoch: 028, Train: 0.5804, Valid: 0.6040, Test: 0.5830\n",
            "Fold: 3, Epoch: 029, Train: 0.5837, Valid: 0.6216, Test: 0.5923\n",
            "Fold: 3, Epoch: 030, Train: 0.5848, Valid: 0.6391, Test: 0.5963\n",
            "Fold: 3, Epoch: 031, Train: 0.5924, Valid: 0.6316, Test: 0.5965\n",
            "Fold: 3, Epoch: 032, Train: 0.5807, Valid: 0.5990, Test: 0.5955\n",
            "Fold: 3, Epoch: 033, Train: 0.5843, Valid: 0.6165, Test: 0.6011\n",
            "Fold: 3, Epoch: 034, Train: 0.5946, Valid: 0.6341, Test: 0.5955\n",
            "Fold: 3, Epoch: 035, Train: 0.5952, Valid: 0.6190, Test: 0.5960\n",
            "Fold: 3, Epoch: 036, Train: 0.5932, Valid: 0.6216, Test: 0.5955\n",
            "Fold: 3, Epoch: 037, Train: 0.5932, Valid: 0.6516, Test: 0.6001\n",
            "Fold: 3, Epoch: 038, Train: 0.5996, Valid: 0.6466, Test: 0.6031\n",
            "Fold: 3, Epoch: 039, Train: 0.5946, Valid: 0.6115, Test: 0.6028\n",
            "Fold: 3, Epoch: 040, Train: 0.6002, Valid: 0.6341, Test: 0.5940\n",
            "Fold: 3, Epoch: 041, Train: 0.5940, Valid: 0.6165, Test: 0.6023\n",
            "Fold: 3, Epoch: 042, Train: 0.6046, Valid: 0.6266, Test: 0.6081\n",
            "Fold: 3, Epoch: 043, Train: 0.6102, Valid: 0.6541, Test: 0.6073\n",
            "Fold: 3, Epoch: 044, Train: 0.5988, Valid: 0.6717, Test: 0.6061\n",
            "Fold: 3, Epoch: 045, Train: 0.6069, Valid: 0.6316, Test: 0.6066\n",
            "Fold: 3, Epoch: 046, Train: 0.6021, Valid: 0.6441, Test: 0.6086\n",
            "Fold: 3, Epoch: 047, Train: 0.6102, Valid: 0.6341, Test: 0.6156\n",
            "Fold: 3, Epoch: 048, Train: 0.6099, Valid: 0.6566, Test: 0.6093\n",
            "Fold: 3, Epoch: 049, Train: 0.6158, Valid: 0.6366, Test: 0.6116\n",
            "Fold: 3, Epoch: 050, Train: 0.6110, Valid: 0.6291, Test: 0.6204\n",
            "Fold: 4, Epoch: 001, Train: 0.5294, Valid: 0.5188, Test: 0.5459\n",
            "Fold: 4, Epoch: 002, Train: 0.5339, Valid: 0.5414, Test: 0.5444\n",
            "Fold: 4, Epoch: 003, Train: 0.5405, Valid: 0.5414, Test: 0.5394\n",
            "Fold: 4, Epoch: 004, Train: 0.5430, Valid: 0.5388, Test: 0.5557\n",
            "Fold: 4, Epoch: 005, Train: 0.5514, Valid: 0.5815, Test: 0.5574\n",
            "Fold: 4, Epoch: 006, Train: 0.5550, Valid: 0.5614, Test: 0.5612\n",
            "Fold: 4, Epoch: 007, Train: 0.5581, Valid: 0.5589, Test: 0.5652\n",
            "Fold: 4, Epoch: 008, Train: 0.5642, Valid: 0.5589, Test: 0.5659\n",
            "Fold: 4, Epoch: 009, Train: 0.5687, Valid: 0.5589, Test: 0.5740\n",
            "Fold: 4, Epoch: 010, Train: 0.5734, Valid: 0.5865, Test: 0.5737\n",
            "Fold: 4, Epoch: 011, Train: 0.5662, Valid: 0.5865, Test: 0.5732\n",
            "Fold: 4, Epoch: 012, Train: 0.5740, Valid: 0.5739, Test: 0.5843\n",
            "Fold: 4, Epoch: 013, Train: 0.5751, Valid: 0.5865, Test: 0.5772\n",
            "Fold: 4, Epoch: 014, Train: 0.5790, Valid: 0.5890, Test: 0.5792\n",
            "Fold: 4, Epoch: 015, Train: 0.5818, Valid: 0.5940, Test: 0.5732\n",
            "Fold: 4, Epoch: 016, Train: 0.5770, Valid: 0.5764, Test: 0.5787\n",
            "Fold: 4, Epoch: 017, Train: 0.5854, Valid: 0.5639, Test: 0.5800\n",
            "Fold: 4, Epoch: 018, Train: 0.5798, Valid: 0.5940, Test: 0.5797\n",
            "Fold: 4, Epoch: 019, Train: 0.5848, Valid: 0.5915, Test: 0.5807\n",
            "Fold: 4, Epoch: 020, Train: 0.5759, Valid: 0.5689, Test: 0.5830\n",
            "Fold: 4, Epoch: 021, Train: 0.5848, Valid: 0.5840, Test: 0.5883\n",
            "Fold: 4, Epoch: 022, Train: 0.5901, Valid: 0.5789, Test: 0.5860\n",
            "Fold: 4, Epoch: 023, Train: 0.5804, Valid: 0.5764, Test: 0.5790\n",
            "Fold: 4, Epoch: 024, Train: 0.5879, Valid: 0.5915, Test: 0.5780\n",
            "Fold: 4, Epoch: 025, Train: 0.5854, Valid: 0.5840, Test: 0.5780\n",
            "Fold: 4, Epoch: 026, Train: 0.5871, Valid: 0.5840, Test: 0.5822\n",
            "Fold: 4, Epoch: 027, Train: 0.5915, Valid: 0.5764, Test: 0.5893\n",
            "Fold: 4, Epoch: 028, Train: 0.5862, Valid: 0.5940, Test: 0.5855\n",
            "Fold: 4, Epoch: 029, Train: 0.5848, Valid: 0.5639, Test: 0.5865\n",
            "Fold: 4, Epoch: 030, Train: 0.5854, Valid: 0.5915, Test: 0.5815\n",
            "Fold: 4, Epoch: 031, Train: 0.5837, Valid: 0.5890, Test: 0.5865\n",
            "Fold: 4, Epoch: 032, Train: 0.5837, Valid: 0.5890, Test: 0.5832\n",
            "Fold: 4, Epoch: 033, Train: 0.5918, Valid: 0.5714, Test: 0.5885\n",
            "Fold: 4, Epoch: 034, Train: 0.5949, Valid: 0.5940, Test: 0.5883\n",
            "Fold: 4, Epoch: 035, Train: 0.5940, Valid: 0.5890, Test: 0.5908\n",
            "Fold: 4, Epoch: 036, Train: 0.5965, Valid: 0.5789, Test: 0.5830\n",
            "Fold: 4, Epoch: 037, Train: 0.5887, Valid: 0.6065, Test: 0.5850\n",
            "Fold: 4, Epoch: 038, Train: 0.5963, Valid: 0.5915, Test: 0.5898\n",
            "Fold: 4, Epoch: 039, Train: 0.5932, Valid: 0.5789, Test: 0.5935\n",
            "Fold: 4, Epoch: 040, Train: 0.5935, Valid: 0.5714, Test: 0.5870\n",
            "Fold: 4, Epoch: 041, Train: 0.5854, Valid: 0.5890, Test: 0.5885\n",
            "Fold: 4, Epoch: 042, Train: 0.5901, Valid: 0.5865, Test: 0.5868\n",
            "Fold: 4, Epoch: 043, Train: 0.5907, Valid: 0.5890, Test: 0.5893\n",
            "Fold: 4, Epoch: 044, Train: 0.5823, Valid: 0.5990, Test: 0.5978\n",
            "Fold: 4, Epoch: 045, Train: 0.5991, Valid: 0.5865, Test: 0.5880\n",
            "Fold: 4, Epoch: 046, Train: 0.5926, Valid: 0.5965, Test: 0.5920\n",
            "Fold: 4, Epoch: 047, Train: 0.6007, Valid: 0.5990, Test: 0.5925\n",
            "Fold: 4, Epoch: 048, Train: 0.5843, Valid: 0.5940, Test: 0.6053\n",
            "Fold: 4, Epoch: 049, Train: 0.5999, Valid: 0.5865, Test: 0.6011\n",
            "Fold: 4, Epoch: 050, Train: 0.6024, Valid: 0.5915, Test: 0.5923\n",
            "Fold: 5, Epoch: 001, Train: 0.4820, Valid: 0.4486, Test: 0.4699\n",
            "Fold: 5, Epoch: 002, Train: 0.4865, Valid: 0.4411, Test: 0.4784\n",
            "Fold: 5, Epoch: 003, Train: 0.4851, Valid: 0.4937, Test: 0.4982\n",
            "Fold: 5, Epoch: 004, Train: 0.5049, Valid: 0.4912, Test: 0.4960\n",
            "Fold: 5, Epoch: 005, Train: 0.5040, Valid: 0.5439, Test: 0.5155\n",
            "Fold: 5, Epoch: 006, Train: 0.5255, Valid: 0.5338, Test: 0.5183\n",
            "Fold: 5, Epoch: 007, Train: 0.5169, Valid: 0.4962, Test: 0.5196\n",
            "Fold: 5, Epoch: 008, Train: 0.5274, Valid: 0.5213, Test: 0.5286\n",
            "Fold: 5, Epoch: 009, Train: 0.5397, Valid: 0.5288, Test: 0.5303\n",
            "Fold: 5, Epoch: 010, Train: 0.5358, Valid: 0.5088, Test: 0.5241\n",
            "Fold: 5, Epoch: 011, Train: 0.5559, Valid: 0.5489, Test: 0.5454\n",
            "Fold: 5, Epoch: 012, Train: 0.5511, Valid: 0.5489, Test: 0.5349\n",
            "Fold: 5, Epoch: 013, Train: 0.5531, Valid: 0.5739, Test: 0.5549\n",
            "Fold: 5, Epoch: 014, Train: 0.5433, Valid: 0.6316, Test: 0.5519\n",
            "Fold: 5, Epoch: 015, Train: 0.5444, Valid: 0.5789, Test: 0.5624\n",
            "Fold: 5, Epoch: 016, Train: 0.5550, Valid: 0.5514, Test: 0.5562\n",
            "Fold: 5, Epoch: 017, Train: 0.5517, Valid: 0.6015, Test: 0.5692\n",
            "Fold: 5, Epoch: 018, Train: 0.5539, Valid: 0.6040, Test: 0.5695\n",
            "Fold: 5, Epoch: 019, Train: 0.5653, Valid: 0.5815, Test: 0.5657\n",
            "Fold: 5, Epoch: 020, Train: 0.5765, Valid: 0.6316, Test: 0.5750\n",
            "Fold: 5, Epoch: 021, Train: 0.5726, Valid: 0.5764, Test: 0.5727\n",
            "Fold: 5, Epoch: 022, Train: 0.5648, Valid: 0.5789, Test: 0.5692\n",
            "Fold: 5, Epoch: 023, Train: 0.5631, Valid: 0.6316, Test: 0.5802\n",
            "Fold: 5, Epoch: 024, Train: 0.5651, Valid: 0.6165, Test: 0.5745\n",
            "Fold: 5, Epoch: 025, Train: 0.5770, Valid: 0.5815, Test: 0.5747\n",
            "Fold: 5, Epoch: 026, Train: 0.5600, Valid: 0.6065, Test: 0.5863\n",
            "Fold: 5, Epoch: 027, Train: 0.5698, Valid: 0.5990, Test: 0.5772\n",
            "Fold: 5, Epoch: 028, Train: 0.5681, Valid: 0.5815, Test: 0.5858\n",
            "Fold: 5, Epoch: 029, Train: 0.5807, Valid: 0.6516, Test: 0.5772\n",
            "Fold: 5, Epoch: 030, Train: 0.5784, Valid: 0.6266, Test: 0.5878\n",
            "Fold: 5, Epoch: 031, Train: 0.5795, Valid: 0.5940, Test: 0.5820\n",
            "Fold: 5, Epoch: 032, Train: 0.5860, Valid: 0.6165, Test: 0.5838\n",
            "Fold: 5, Epoch: 033, Train: 0.5787, Valid: 0.6065, Test: 0.5868\n",
            "Fold: 5, Epoch: 034, Train: 0.5832, Valid: 0.6341, Test: 0.5870\n",
            "Fold: 5, Epoch: 035, Train: 0.5734, Valid: 0.6065, Test: 0.5853\n",
            "Fold: 5, Epoch: 036, Train: 0.5787, Valid: 0.6441, Test: 0.5802\n",
            "Fold: 5, Epoch: 037, Train: 0.5812, Valid: 0.6366, Test: 0.5822\n",
            "Fold: 5, Epoch: 038, Train: 0.5776, Valid: 0.6241, Test: 0.5918\n",
            "Fold: 5, Epoch: 039, Train: 0.5879, Valid: 0.6115, Test: 0.5930\n",
            "Fold: 5, Epoch: 040, Train: 0.5801, Valid: 0.6040, Test: 0.5955\n",
            "Fold: 5, Epoch: 041, Train: 0.5952, Valid: 0.6316, Test: 0.5883\n",
            "Fold: 5, Epoch: 042, Train: 0.5748, Valid: 0.6165, Test: 0.5923\n",
            "Fold: 5, Epoch: 043, Train: 0.5913, Valid: 0.6617, Test: 0.5950\n",
            "Fold: 5, Epoch: 044, Train: 0.5840, Valid: 0.6316, Test: 0.5935\n",
            "Fold: 5, Epoch: 045, Train: 0.5862, Valid: 0.6366, Test: 0.5913\n",
            "Fold: 5, Epoch: 046, Train: 0.6010, Valid: 0.6441, Test: 0.5908\n",
            "Fold: 5, Epoch: 047, Train: 0.5829, Valid: 0.6516, Test: 0.5948\n",
            "Fold: 5, Epoch: 048, Train: 0.5798, Valid: 0.6241, Test: 0.5948\n",
            "Fold: 5, Epoch: 049, Train: 0.5915, Valid: 0.6316, Test: 0.5993\n",
            "Fold: 5, Epoch: 050, Train: 0.5960, Valid: 0.6291, Test: 0.5983\n",
            "Fold: 6, Epoch: 001, Train: 0.5316, Valid: 0.5288, Test: 0.5414\n",
            "Fold: 6, Epoch: 002, Train: 0.5280, Valid: 0.5514, Test: 0.5354\n",
            "Fold: 6, Epoch: 003, Train: 0.5405, Valid: 0.5489, Test: 0.5291\n",
            "Fold: 6, Epoch: 004, Train: 0.5447, Valid: 0.5439, Test: 0.5306\n",
            "Fold: 6, Epoch: 005, Train: 0.5366, Valid: 0.5038, Test: 0.5441\n",
            "Fold: 6, Epoch: 006, Train: 0.5341, Valid: 0.5589, Test: 0.5401\n",
            "Fold: 6, Epoch: 007, Train: 0.5411, Valid: 0.5789, Test: 0.5464\n",
            "Fold: 6, Epoch: 008, Train: 0.5316, Valid: 0.5815, Test: 0.5474\n",
            "Fold: 6, Epoch: 009, Train: 0.5372, Valid: 0.5865, Test: 0.5429\n",
            "Fold: 6, Epoch: 010, Train: 0.5606, Valid: 0.5589, Test: 0.5489\n",
            "Fold: 6, Epoch: 011, Train: 0.5570, Valid: 0.5965, Test: 0.5517\n",
            "Fold: 6, Epoch: 012, Train: 0.5581, Valid: 0.5363, Test: 0.5647\n",
            "Fold: 6, Epoch: 013, Train: 0.5517, Valid: 0.5564, Test: 0.5629\n",
            "Fold: 6, Epoch: 014, Train: 0.5536, Valid: 0.5388, Test: 0.5597\n",
            "Fold: 6, Epoch: 015, Train: 0.5545, Valid: 0.5539, Test: 0.5451\n",
            "Fold: 6, Epoch: 016, Train: 0.5559, Valid: 0.5865, Test: 0.5607\n",
            "Fold: 6, Epoch: 017, Train: 0.5609, Valid: 0.5714, Test: 0.5584\n",
            "Fold: 6, Epoch: 018, Train: 0.5548, Valid: 0.5589, Test: 0.5617\n",
            "Fold: 6, Epoch: 019, Train: 0.5634, Valid: 0.5664, Test: 0.5569\n",
            "Fold: 6, Epoch: 020, Train: 0.5701, Valid: 0.5714, Test: 0.5622\n",
            "Fold: 6, Epoch: 021, Train: 0.5578, Valid: 0.5388, Test: 0.5539\n",
            "Fold: 6, Epoch: 022, Train: 0.5678, Valid: 0.5739, Test: 0.5637\n",
            "Fold: 6, Epoch: 023, Train: 0.5667, Valid: 0.5965, Test: 0.5649\n",
            "Fold: 6, Epoch: 024, Train: 0.5740, Valid: 0.5789, Test: 0.5662\n",
            "Fold: 6, Epoch: 025, Train: 0.5600, Valid: 0.5639, Test: 0.5712\n",
            "Fold: 6, Epoch: 026, Train: 0.5734, Valid: 0.5714, Test: 0.5727\n",
            "Fold: 6, Epoch: 027, Train: 0.5756, Valid: 0.5990, Test: 0.5735\n",
            "Fold: 6, Epoch: 028, Train: 0.5645, Valid: 0.5664, Test: 0.5735\n",
            "Fold: 6, Epoch: 029, Train: 0.5678, Valid: 0.5764, Test: 0.5750\n",
            "Fold: 6, Epoch: 030, Train: 0.5779, Valid: 0.5789, Test: 0.5770\n",
            "Fold: 6, Epoch: 031, Train: 0.5748, Valid: 0.5965, Test: 0.5740\n",
            "Fold: 6, Epoch: 032, Train: 0.5695, Valid: 0.6040, Test: 0.5785\n",
            "Fold: 6, Epoch: 033, Train: 0.5779, Valid: 0.5614, Test: 0.5868\n",
            "Fold: 6, Epoch: 034, Train: 0.5840, Valid: 0.5614, Test: 0.5767\n",
            "Fold: 6, Epoch: 035, Train: 0.5779, Valid: 0.5815, Test: 0.5747\n",
            "Fold: 6, Epoch: 036, Train: 0.5754, Valid: 0.5990, Test: 0.5840\n",
            "Fold: 6, Epoch: 037, Train: 0.5798, Valid: 0.5915, Test: 0.5770\n",
            "Fold: 6, Epoch: 038, Train: 0.5745, Valid: 0.5789, Test: 0.5725\n",
            "Fold: 6, Epoch: 039, Train: 0.5832, Valid: 0.6040, Test: 0.5747\n",
            "Fold: 6, Epoch: 040, Train: 0.5770, Valid: 0.5639, Test: 0.5772\n",
            "Fold: 6, Epoch: 041, Train: 0.5890, Valid: 0.5915, Test: 0.5858\n",
            "Fold: 6, Epoch: 042, Train: 0.5868, Valid: 0.5915, Test: 0.5752\n",
            "Fold: 6, Epoch: 043, Train: 0.5834, Valid: 0.5915, Test: 0.5747\n",
            "Fold: 6, Epoch: 044, Train: 0.5779, Valid: 0.5840, Test: 0.5905\n",
            "Fold: 6, Epoch: 045, Train: 0.5818, Valid: 0.6065, Test: 0.5950\n",
            "Fold: 6, Epoch: 046, Train: 0.5818, Valid: 0.6065, Test: 0.5805\n",
            "Fold: 6, Epoch: 047, Train: 0.5926, Valid: 0.5915, Test: 0.5807\n",
            "Fold: 6, Epoch: 048, Train: 0.5926, Valid: 0.5990, Test: 0.5878\n",
            "Fold: 6, Epoch: 049, Train: 0.5868, Valid: 0.6241, Test: 0.5913\n",
            "Fold: 6, Epoch: 050, Train: 0.5879, Valid: 0.5965, Test: 0.5807\n",
            "Fold: 7, Epoch: 001, Train: 0.5603, Valid: 0.5338, Test: 0.5594\n",
            "Fold: 7, Epoch: 002, Train: 0.5645, Valid: 0.5238, Test: 0.5592\n",
            "Fold: 7, Epoch: 003, Train: 0.5617, Valid: 0.5138, Test: 0.5592\n",
            "Fold: 7, Epoch: 004, Train: 0.5606, Valid: 0.5263, Test: 0.5569\n",
            "Fold: 7, Epoch: 005, Train: 0.5656, Valid: 0.5213, Test: 0.5609\n",
            "Fold: 7, Epoch: 006, Train: 0.5642, Valid: 0.5363, Test: 0.5582\n",
            "Fold: 7, Epoch: 007, Train: 0.5600, Valid: 0.5338, Test: 0.5567\n",
            "Fold: 7, Epoch: 008, Train: 0.5626, Valid: 0.5263, Test: 0.5564\n",
            "Fold: 7, Epoch: 009, Train: 0.5631, Valid: 0.5388, Test: 0.5612\n",
            "Fold: 7, Epoch: 010, Train: 0.5606, Valid: 0.5238, Test: 0.5577\n",
            "Fold: 7, Epoch: 011, Train: 0.5609, Valid: 0.5238, Test: 0.5574\n",
            "Fold: 7, Epoch: 012, Train: 0.5620, Valid: 0.5213, Test: 0.5670\n",
            "Fold: 7, Epoch: 013, Train: 0.5665, Valid: 0.5363, Test: 0.5642\n",
            "Fold: 7, Epoch: 014, Train: 0.5684, Valid: 0.5238, Test: 0.5622\n",
            "Fold: 7, Epoch: 015, Train: 0.5701, Valid: 0.5213, Test: 0.5707\n",
            "Fold: 7, Epoch: 016, Train: 0.5659, Valid: 0.5263, Test: 0.5629\n",
            "Fold: 7, Epoch: 017, Train: 0.5773, Valid: 0.5363, Test: 0.5675\n",
            "Fold: 7, Epoch: 018, Train: 0.5681, Valid: 0.5238, Test: 0.5715\n",
            "Fold: 7, Epoch: 019, Train: 0.5723, Valid: 0.5414, Test: 0.5730\n",
            "Fold: 7, Epoch: 020, Train: 0.5701, Valid: 0.5414, Test: 0.5667\n",
            "Fold: 7, Epoch: 021, Train: 0.5717, Valid: 0.5388, Test: 0.5717\n",
            "Fold: 7, Epoch: 022, Train: 0.5793, Valid: 0.5388, Test: 0.5722\n",
            "Fold: 7, Epoch: 023, Train: 0.5726, Valid: 0.5439, Test: 0.5750\n",
            "Fold: 7, Epoch: 024, Train: 0.5776, Valid: 0.5414, Test: 0.5720\n",
            "Fold: 7, Epoch: 025, Train: 0.5809, Valid: 0.5539, Test: 0.5757\n",
            "Fold: 7, Epoch: 026, Train: 0.5815, Valid: 0.5338, Test: 0.5745\n",
            "Fold: 7, Epoch: 027, Train: 0.5801, Valid: 0.5539, Test: 0.5767\n",
            "Fold: 7, Epoch: 028, Train: 0.5815, Valid: 0.5539, Test: 0.5727\n",
            "Fold: 7, Epoch: 029, Train: 0.5860, Valid: 0.5639, Test: 0.5827\n",
            "Fold: 7, Epoch: 030, Train: 0.5904, Valid: 0.5313, Test: 0.5780\n",
            "Fold: 7, Epoch: 031, Train: 0.5890, Valid: 0.5514, Test: 0.5785\n",
            "Fold: 7, Epoch: 032, Train: 0.5896, Valid: 0.5514, Test: 0.5853\n",
            "Fold: 7, Epoch: 033, Train: 0.5904, Valid: 0.5489, Test: 0.5820\n",
            "Fold: 7, Epoch: 034, Train: 0.5848, Valid: 0.5464, Test: 0.5843\n",
            "Fold: 7, Epoch: 035, Train: 0.5893, Valid: 0.5263, Test: 0.5868\n",
            "Fold: 7, Epoch: 036, Train: 0.5904, Valid: 0.5639, Test: 0.5810\n",
            "Fold: 7, Epoch: 037, Train: 0.5904, Valid: 0.5589, Test: 0.5825\n",
            "Fold: 7, Epoch: 038, Train: 0.5890, Valid: 0.5915, Test: 0.5845\n",
            "Fold: 7, Epoch: 039, Train: 0.5846, Valid: 0.5514, Test: 0.5940\n",
            "Fold: 7, Epoch: 040, Train: 0.5918, Valid: 0.5639, Test: 0.5895\n",
            "Fold: 7, Epoch: 041, Train: 0.5882, Valid: 0.5714, Test: 0.5895\n",
            "Fold: 7, Epoch: 042, Train: 0.5910, Valid: 0.5739, Test: 0.5905\n",
            "Fold: 7, Epoch: 043, Train: 0.5887, Valid: 0.5840, Test: 0.5915\n",
            "Fold: 7, Epoch: 044, Train: 0.5943, Valid: 0.5489, Test: 0.5890\n",
            "Fold: 7, Epoch: 045, Train: 0.5954, Valid: 0.5539, Test: 0.5895\n",
            "Fold: 7, Epoch: 046, Train: 0.6013, Valid: 0.5589, Test: 0.5900\n",
            "Fold: 7, Epoch: 047, Train: 0.5960, Valid: 0.5664, Test: 0.6016\n",
            "Fold: 7, Epoch: 048, Train: 0.5915, Valid: 0.5815, Test: 0.5910\n",
            "Fold: 7, Epoch: 049, Train: 0.5993, Valid: 0.5664, Test: 0.5980\n",
            "Fold: 7, Epoch: 050, Train: 0.5943, Valid: 0.5639, Test: 0.5827\n",
            "Fold: 8, Epoch: 001, Train: 0.5394, Valid: 0.4912, Test: 0.5321\n",
            "Fold: 8, Epoch: 002, Train: 0.5439, Valid: 0.5414, Test: 0.5374\n",
            "Fold: 8, Epoch: 003, Train: 0.5428, Valid: 0.5388, Test: 0.5464\n",
            "Fold: 8, Epoch: 004, Train: 0.5481, Valid: 0.5388, Test: 0.5481\n",
            "Fold: 8, Epoch: 005, Train: 0.5620, Valid: 0.5363, Test: 0.5494\n",
            "Fold: 8, Epoch: 006, Train: 0.5634, Valid: 0.5338, Test: 0.5557\n",
            "Fold: 8, Epoch: 007, Train: 0.5620, Valid: 0.5764, Test: 0.5639\n",
            "Fold: 8, Epoch: 008, Train: 0.5620, Valid: 0.5213, Test: 0.5632\n",
            "Fold: 8, Epoch: 009, Train: 0.5628, Valid: 0.5564, Test: 0.5617\n",
            "Fold: 8, Epoch: 010, Train: 0.5612, Valid: 0.5363, Test: 0.5670\n",
            "Fold: 8, Epoch: 011, Train: 0.5737, Valid: 0.5388, Test: 0.5682\n",
            "Fold: 8, Epoch: 012, Train: 0.5670, Valid: 0.5589, Test: 0.5697\n",
            "Fold: 8, Epoch: 013, Train: 0.5731, Valid: 0.5689, Test: 0.5654\n",
            "Fold: 8, Epoch: 014, Train: 0.5701, Valid: 0.5614, Test: 0.5707\n",
            "Fold: 8, Epoch: 015, Train: 0.5740, Valid: 0.5539, Test: 0.5737\n",
            "Fold: 8, Epoch: 016, Train: 0.5756, Valid: 0.5689, Test: 0.5710\n",
            "Fold: 8, Epoch: 017, Train: 0.5726, Valid: 0.5589, Test: 0.5795\n",
            "Fold: 8, Epoch: 018, Train: 0.5784, Valid: 0.5689, Test: 0.5732\n",
            "Fold: 8, Epoch: 019, Train: 0.5756, Valid: 0.5714, Test: 0.5795\n",
            "Fold: 8, Epoch: 020, Train: 0.5779, Valid: 0.5639, Test: 0.5810\n",
            "Fold: 8, Epoch: 021, Train: 0.5843, Valid: 0.5614, Test: 0.5745\n",
            "Fold: 8, Epoch: 022, Train: 0.5762, Valid: 0.5689, Test: 0.5752\n",
            "Fold: 8, Epoch: 023, Train: 0.5834, Valid: 0.5614, Test: 0.5772\n",
            "Fold: 8, Epoch: 024, Train: 0.5798, Valid: 0.5714, Test: 0.5815\n",
            "Fold: 8, Epoch: 025, Train: 0.5798, Valid: 0.5664, Test: 0.5772\n",
            "Fold: 8, Epoch: 026, Train: 0.5823, Valid: 0.5664, Test: 0.5707\n",
            "Fold: 8, Epoch: 027, Train: 0.5743, Valid: 0.5539, Test: 0.5750\n",
            "Fold: 8, Epoch: 028, Train: 0.5818, Valid: 0.5639, Test: 0.5772\n",
            "Fold: 8, Epoch: 029, Train: 0.5798, Valid: 0.5564, Test: 0.5835\n",
            "Fold: 8, Epoch: 030, Train: 0.5832, Valid: 0.5539, Test: 0.5820\n",
            "Fold: 8, Epoch: 031, Train: 0.5899, Valid: 0.5739, Test: 0.5875\n",
            "Fold: 8, Epoch: 032, Train: 0.5782, Valid: 0.5664, Test: 0.5838\n",
            "Fold: 8, Epoch: 033, Train: 0.5829, Valid: 0.5714, Test: 0.5845\n",
            "Fold: 8, Epoch: 034, Train: 0.5823, Valid: 0.5940, Test: 0.5850\n",
            "Fold: 8, Epoch: 035, Train: 0.5862, Valid: 0.5764, Test: 0.5787\n",
            "Fold: 8, Epoch: 036, Train: 0.5826, Valid: 0.5689, Test: 0.5885\n",
            "Fold: 8, Epoch: 037, Train: 0.5782, Valid: 0.5639, Test: 0.5848\n",
            "Fold: 8, Epoch: 038, Train: 0.5809, Valid: 0.5764, Test: 0.5885\n",
            "Fold: 8, Epoch: 039, Train: 0.5921, Valid: 0.5915, Test: 0.5817\n",
            "Fold: 8, Epoch: 040, Train: 0.5793, Valid: 0.5714, Test: 0.5853\n",
            "Fold: 8, Epoch: 041, Train: 0.5848, Valid: 0.5789, Test: 0.5845\n",
            "Fold: 8, Epoch: 042, Train: 0.5829, Valid: 0.5815, Test: 0.5873\n",
            "Fold: 8, Epoch: 043, Train: 0.5893, Valid: 0.5764, Test: 0.5888\n",
            "Fold: 8, Epoch: 044, Train: 0.5860, Valid: 0.5739, Test: 0.5845\n",
            "Fold: 8, Epoch: 045, Train: 0.5854, Valid: 0.5539, Test: 0.5843\n",
            "Fold: 8, Epoch: 046, Train: 0.5851, Valid: 0.5739, Test: 0.5807\n",
            "Fold: 8, Epoch: 047, Train: 0.5876, Valid: 0.5664, Test: 0.5898\n",
            "Fold: 8, Epoch: 048, Train: 0.5896, Valid: 0.5664, Test: 0.5860\n",
            "Fold: 8, Epoch: 049, Train: 0.5921, Valid: 0.5865, Test: 0.5870\n",
            "Fold: 8, Epoch: 050, Train: 0.5851, Valid: 0.5689, Test: 0.5898\n",
            "Fold: 9, Epoch: 001, Train: 0.4627, Valid: 0.4523, Test: 0.4814\n",
            "Fold: 9, Epoch: 002, Train: 0.4805, Valid: 0.4799, Test: 0.4739\n",
            "Fold: 9, Epoch: 003, Train: 0.5003, Valid: 0.5025, Test: 0.4910\n",
            "Fold: 9, Epoch: 004, Train: 0.5072, Valid: 0.5050, Test: 0.5125\n",
            "Fold: 9, Epoch: 005, Train: 0.5150, Valid: 0.5427, Test: 0.5188\n",
            "Fold: 9, Epoch: 006, Train: 0.5279, Valid: 0.5553, Test: 0.5176\n",
            "Fold: 9, Epoch: 007, Train: 0.5368, Valid: 0.5075, Test: 0.5308\n",
            "Fold: 9, Epoch: 008, Train: 0.5504, Valid: 0.5628, Test: 0.5303\n",
            "Fold: 9, Epoch: 009, Train: 0.5462, Valid: 0.4899, Test: 0.5509\n",
            "Fold: 9, Epoch: 010, Train: 0.5568, Valid: 0.5452, Test: 0.5629\n",
            "Fold: 9, Epoch: 011, Train: 0.5616, Valid: 0.5503, Test: 0.5597\n",
            "Fold: 9, Epoch: 012, Train: 0.5585, Valid: 0.5377, Test: 0.5594\n",
            "Fold: 9, Epoch: 013, Train: 0.5738, Valid: 0.5477, Test: 0.5637\n",
            "Fold: 9, Epoch: 014, Train: 0.5694, Valid: 0.5603, Test: 0.5629\n",
            "Fold: 9, Epoch: 015, Train: 0.5627, Valid: 0.5553, Test: 0.5742\n",
            "Fold: 9, Epoch: 016, Train: 0.5813, Valid: 0.5327, Test: 0.5690\n",
            "Fold: 9, Epoch: 017, Train: 0.5889, Valid: 0.5628, Test: 0.5822\n",
            "Fold: 9, Epoch: 018, Train: 0.5727, Valid: 0.5653, Test: 0.5685\n",
            "Fold: 9, Epoch: 019, Train: 0.5786, Valid: 0.5678, Test: 0.5727\n",
            "Fold: 9, Epoch: 020, Train: 0.5669, Valid: 0.5427, Test: 0.5805\n",
            "Fold: 9, Epoch: 021, Train: 0.5763, Valid: 0.5879, Test: 0.5654\n",
            "Fold: 9, Epoch: 022, Train: 0.5691, Valid: 0.5452, Test: 0.5822\n",
            "Fold: 9, Epoch: 023, Train: 0.5791, Valid: 0.5628, Test: 0.5692\n",
            "Fold: 9, Epoch: 024, Train: 0.5838, Valid: 0.5603, Test: 0.5845\n",
            "Fold: 9, Epoch: 025, Train: 0.5816, Valid: 0.5528, Test: 0.5747\n",
            "Fold: 9, Epoch: 026, Train: 0.5855, Valid: 0.5427, Test: 0.5883\n",
            "Fold: 9, Epoch: 027, Train: 0.5880, Valid: 0.5628, Test: 0.5848\n",
            "Fold: 9, Epoch: 028, Train: 0.5942, Valid: 0.5553, Test: 0.5725\n",
            "Fold: 9, Epoch: 029, Train: 0.5914, Valid: 0.5653, Test: 0.5795\n",
            "Fold: 9, Epoch: 030, Train: 0.5903, Valid: 0.5477, Test: 0.5938\n",
            "Fold: 9, Epoch: 031, Train: 0.5922, Valid: 0.5553, Test: 0.5903\n",
            "Fold: 9, Epoch: 032, Train: 0.5836, Valid: 0.5628, Test: 0.5840\n",
            "Fold: 9, Epoch: 033, Train: 0.5847, Valid: 0.5829, Test: 0.5853\n",
            "Fold: 9, Epoch: 034, Train: 0.5967, Valid: 0.5704, Test: 0.5893\n",
            "Fold: 9, Epoch: 035, Train: 0.5891, Valid: 0.5553, Test: 0.5890\n",
            "Fold: 9, Epoch: 036, Train: 0.5897, Valid: 0.5603, Test: 0.5895\n",
            "Fold: 9, Epoch: 037, Train: 0.5944, Valid: 0.5503, Test: 0.5863\n",
            "Fold: 9, Epoch: 038, Train: 0.5891, Valid: 0.5653, Test: 0.5908\n",
            "Fold: 9, Epoch: 039, Train: 0.5975, Valid: 0.5452, Test: 0.5938\n",
            "Fold: 9, Epoch: 040, Train: 0.5961, Valid: 0.5528, Test: 0.5888\n",
            "Fold: 9, Epoch: 041, Train: 0.5900, Valid: 0.5628, Test: 0.5930\n",
            "Fold: 9, Epoch: 042, Train: 0.5942, Valid: 0.5603, Test: 0.5925\n",
            "Fold: 9, Epoch: 043, Train: 0.5967, Valid: 0.5377, Test: 0.5895\n",
            "Fold: 9, Epoch: 044, Train: 0.5914, Valid: 0.5427, Test: 0.5965\n",
            "Fold: 9, Epoch: 045, Train: 0.5958, Valid: 0.5528, Test: 0.5955\n",
            "Fold: 9, Epoch: 046, Train: 0.5942, Valid: 0.5879, Test: 0.5945\n",
            "Fold: 9, Epoch: 047, Train: 0.5947, Valid: 0.5553, Test: 0.5965\n",
            "Fold: 9, Epoch: 048, Train: 0.6039, Valid: 0.5553, Test: 0.5940\n",
            "Fold: 9, Epoch: 049, Train: 0.5967, Valid: 0.5729, Test: 0.5925\n",
            "Fold: 9, Epoch: 050, Train: 0.6014, Valid: 0.5452, Test: 0.5945\n",
            "Fold: 10, Epoch: 001, Train: 0.4348, Valid: 0.3995, Test: 0.4313\n",
            "Fold: 10, Epoch: 002, Train: 0.4326, Valid: 0.3894, Test: 0.4275\n",
            "Fold: 10, Epoch: 003, Train: 0.4435, Valid: 0.3920, Test: 0.4295\n",
            "Fold: 10, Epoch: 004, Train: 0.4393, Valid: 0.3945, Test: 0.4393\n",
            "Fold: 10, Epoch: 005, Train: 0.4485, Valid: 0.4045, Test: 0.4386\n",
            "Fold: 10, Epoch: 006, Train: 0.4518, Valid: 0.4372, Test: 0.4536\n",
            "Fold: 10, Epoch: 007, Train: 0.4627, Valid: 0.4296, Test: 0.4682\n",
            "Fold: 10, Epoch: 008, Train: 0.4844, Valid: 0.4221, Test: 0.4714\n",
            "Fold: 10, Epoch: 009, Train: 0.4889, Valid: 0.4749, Test: 0.4774\n",
            "Fold: 10, Epoch: 010, Train: 0.4958, Valid: 0.4724, Test: 0.4867\n",
            "Fold: 10, Epoch: 011, Train: 0.4972, Valid: 0.4698, Test: 0.4972\n",
            "Fold: 10, Epoch: 012, Train: 0.4875, Valid: 0.4975, Test: 0.5043\n",
            "Fold: 10, Epoch: 013, Train: 0.4919, Valid: 0.4724, Test: 0.5085\n",
            "Fold: 10, Epoch: 014, Train: 0.5053, Valid: 0.5427, Test: 0.5145\n",
            "Fold: 10, Epoch: 015, Train: 0.5125, Valid: 0.5126, Test: 0.5088\n",
            "Fold: 10, Epoch: 016, Train: 0.5173, Valid: 0.4799, Test: 0.5233\n",
            "Fold: 10, Epoch: 017, Train: 0.5201, Valid: 0.5050, Test: 0.5065\n",
            "Fold: 10, Epoch: 018, Train: 0.5150, Valid: 0.5000, Test: 0.5188\n",
            "Fold: 10, Epoch: 019, Train: 0.5011, Valid: 0.4673, Test: 0.5125\n",
            "Fold: 10, Epoch: 020, Train: 0.5117, Valid: 0.5528, Test: 0.5108\n",
            "Fold: 10, Epoch: 021, Train: 0.5100, Valid: 0.5226, Test: 0.5140\n",
            "Fold: 10, Epoch: 022, Train: 0.5326, Valid: 0.5804, Test: 0.5291\n",
            "Fold: 10, Epoch: 023, Train: 0.5228, Valid: 0.5477, Test: 0.5258\n",
            "Fold: 10, Epoch: 024, Train: 0.5379, Valid: 0.5452, Test: 0.5293\n",
            "Fold: 10, Epoch: 025, Train: 0.5309, Valid: 0.5477, Test: 0.5326\n",
            "Fold: 10, Epoch: 026, Train: 0.5265, Valid: 0.5653, Test: 0.5409\n",
            "Fold: 10, Epoch: 027, Train: 0.5412, Valid: 0.5603, Test: 0.5331\n",
            "Fold: 10, Epoch: 028, Train: 0.5362, Valid: 0.5503, Test: 0.5371\n",
            "Fold: 10, Epoch: 029, Train: 0.5376, Valid: 0.5829, Test: 0.5609\n",
            "Fold: 10, Epoch: 030, Train: 0.5409, Valid: 0.5578, Test: 0.5539\n",
            "Fold: 10, Epoch: 031, Train: 0.5331, Valid: 0.5352, Test: 0.5494\n",
            "Fold: 10, Epoch: 032, Train: 0.5549, Valid: 0.5603, Test: 0.5446\n",
            "Fold: 10, Epoch: 033, Train: 0.5448, Valid: 0.5176, Test: 0.5537\n",
            "Fold: 10, Epoch: 034, Train: 0.5529, Valid: 0.5578, Test: 0.5456\n",
            "Fold: 10, Epoch: 035, Train: 0.5354, Valid: 0.6005, Test: 0.5544\n",
            "Fold: 10, Epoch: 036, Train: 0.5585, Valid: 0.5302, Test: 0.5539\n",
            "Fold: 10, Epoch: 037, Train: 0.5521, Valid: 0.5553, Test: 0.5512\n",
            "Fold: 10, Epoch: 038, Train: 0.5563, Valid: 0.6055, Test: 0.5592\n",
            "Fold: 10, Epoch: 039, Train: 0.5560, Valid: 0.5704, Test: 0.5604\n",
            "Fold: 10, Epoch: 040, Train: 0.5680, Valid: 0.5528, Test: 0.5652\n",
            "Fold: 10, Epoch: 041, Train: 0.5741, Valid: 0.5653, Test: 0.5647\n",
            "Fold: 10, Epoch: 042, Train: 0.5457, Valid: 0.5377, Test: 0.5587\n",
            "Fold: 10, Epoch: 043, Train: 0.5671, Valid: 0.5628, Test: 0.5705\n",
            "Fold: 10, Epoch: 044, Train: 0.5565, Valid: 0.5754, Test: 0.5574\n",
            "Fold: 10, Epoch: 045, Train: 0.5493, Valid: 0.5729, Test: 0.5609\n",
            "Fold: 10, Epoch: 046, Train: 0.5713, Valid: 0.5955, Test: 0.5574\n",
            "Fold: 10, Epoch: 047, Train: 0.5532, Valid: 0.5754, Test: 0.5637\n",
            "Fold: 10, Epoch: 048, Train: 0.5513, Valid: 0.5955, Test: 0.5712\n",
            "Fold: 10, Epoch: 049, Train: 0.5663, Valid: 0.5905, Test: 0.5790\n",
            "Fold: 10, Epoch: 050, Train: 0.5685, Valid: 0.5955, Test: 0.5612\n",
            "\n",
            "Elapsed Time:  355.79845213890076\n"
          ]
        }
      ],
      "source": [
        "main('SAGE', dataset_graph, test_graph, model_dir, result_dir, k_hop=1, k_fold=10, n_epo=50, save=True)"
      ],
      "id": "db851743"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bed00480",
        "outputId": "edcd7830-358d-4d36-bc75-a65d6c5f200b",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4923, Valid: 0.4712, Test: 0.4957\n",
            "Fold: 1, Epoch: 011, Train: 0.7216, Valid: 0.7343, Test: 0.7129\n",
            "Fold: 1, Epoch: 021, Train: 0.7386, Valid: 0.7444, Test: 0.7482\n",
            "Fold: 1, Epoch: 031, Train: 0.7581, Valid: 0.7769, Test: 0.7578\n",
            "Fold: 1, Epoch: 041, Train: 0.7746, Valid: 0.7820, Test: 0.7706\n",
            "Fold: 2, Epoch: 001, Train: 0.8066, Valid: 0.7920, Test: 0.8054\n",
            "Fold: 2, Epoch: 011, Train: 0.8122, Valid: 0.8145, Test: 0.8175\n",
            "Fold: 2, Epoch: 021, Train: 0.8412, Valid: 0.8195, Test: 0.8363\n",
            "Fold: 2, Epoch: 031, Train: 0.8520, Valid: 0.8296, Test: 0.8538\n",
            "Fold: 2, Epoch: 041, Train: 0.8704, Valid: 0.8296, Test: 0.8666\n",
            "Fold: 3, Epoch: 001, Train: 0.8724, Valid: 0.8446, Test: 0.8706\n",
            "Fold: 3, Epoch: 011, Train: 0.8780, Valid: 0.8471, Test: 0.8786\n",
            "Fold: 3, Epoch: 021, Train: 0.8849, Valid: 0.8722, Test: 0.8804\n",
            "Fold: 3, Epoch: 031, Train: 0.8913, Valid: 0.8772, Test: 0.8917\n",
            "Fold: 3, Epoch: 041, Train: 0.8997, Valid: 0.8772, Test: 0.8907\n",
            "Fold: 4, Epoch: 001, Train: 0.8927, Valid: 0.9098, Test: 0.8934\n",
            "Fold: 4, Epoch: 011, Train: 0.8986, Valid: 0.9098, Test: 0.9010\n",
            "Fold: 4, Epoch: 021, Train: 0.8975, Valid: 0.8997, Test: 0.8992\n",
            "Fold: 4, Epoch: 031, Train: 0.9106, Valid: 0.9123, Test: 0.9090\n",
            "Fold: 4, Epoch: 041, Train: 0.9125, Valid: 0.9048, Test: 0.9090\n",
            "Fold: 5, Epoch: 001, Train: 0.9125, Valid: 0.9223, Test: 0.9150\n",
            "Fold: 5, Epoch: 011, Train: 0.9175, Valid: 0.9273, Test: 0.9160\n",
            "Fold: 5, Epoch: 021, Train: 0.9122, Valid: 0.9248, Test: 0.9195\n",
            "Fold: 5, Epoch: 031, Train: 0.9195, Valid: 0.9248, Test: 0.9195\n",
            "Fold: 5, Epoch: 041, Train: 0.9223, Valid: 0.9248, Test: 0.9228\n",
            "Fold: 6, Epoch: 001, Train: 0.9256, Valid: 0.9123, Test: 0.9243\n",
            "Fold: 6, Epoch: 011, Train: 0.9315, Valid: 0.9273, Test: 0.9255\n",
            "Fold: 6, Epoch: 021, Train: 0.9284, Valid: 0.8972, Test: 0.9280\n",
            "Fold: 6, Epoch: 031, Train: 0.9337, Valid: 0.9198, Test: 0.9288\n",
            "Fold: 6, Epoch: 041, Train: 0.9348, Valid: 0.9073, Test: 0.9303\n",
            "Fold: 7, Epoch: 001, Train: 0.9315, Valid: 0.9549, Test: 0.9353\n",
            "Fold: 7, Epoch: 011, Train: 0.9348, Valid: 0.9323, Test: 0.9363\n",
            "Fold: 7, Epoch: 021, Train: 0.9398, Valid: 0.9348, Test: 0.9421\n",
            "Fold: 7, Epoch: 031, Train: 0.9401, Valid: 0.9373, Test: 0.9373\n",
            "Fold: 7, Epoch: 041, Train: 0.9485, Valid: 0.9273, Test: 0.9428\n",
            "Fold: 8, Epoch: 001, Train: 0.9381, Valid: 0.9474, Test: 0.9401\n",
            "Fold: 8, Epoch: 011, Train: 0.9437, Valid: 0.9499, Test: 0.9468\n",
            "Fold: 8, Epoch: 021, Train: 0.9407, Valid: 0.9449, Test: 0.9441\n",
            "Fold: 8, Epoch: 031, Train: 0.9306, Valid: 0.9348, Test: 0.9330\n",
            "Fold: 8, Epoch: 041, Train: 0.9501, Valid: 0.9499, Test: 0.9524\n",
            "Fold: 9, Epoch: 001, Train: 0.9518, Valid: 0.9271, Test: 0.9516\n",
            "Fold: 9, Epoch: 011, Train: 0.9404, Valid: 0.9095, Test: 0.9388\n",
            "Fold: 9, Epoch: 021, Train: 0.9535, Valid: 0.9322, Test: 0.9539\n",
            "Fold: 9, Epoch: 031, Train: 0.9577, Valid: 0.9347, Test: 0.9549\n",
            "Fold: 9, Epoch: 041, Train: 0.9568, Valid: 0.9221, Test: 0.9531\n",
            "Fold: 10, Epoch: 001, Train: 0.9543, Valid: 0.9648, Test: 0.9554\n",
            "Fold: 10, Epoch: 011, Train: 0.9602, Valid: 0.9749, Test: 0.9569\n",
            "Fold: 10, Epoch: 021, Train: 0.9571, Valid: 0.9673, Test: 0.9616\n",
            "Fold: 10, Epoch: 031, Train: 0.9468, Valid: 0.9523, Test: 0.9451\n",
            "Fold: 10, Epoch: 041, Train: 0.9618, Valid: 0.9673, Test: 0.9584\n",
            "\n",
            "Elapsed Time:  759.5241258144379\n"
          ]
        }
      ],
      "source": [
        "main('SAGE', dataset_graph, test_graph, model_dir, result_dir, k_hop=2, k_fold=10, n_epo=50)"
      ],
      "id": "bed00480"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5219c00",
        "outputId": "6e088b8e-46b5-4eae-9a30-11edf1e06b9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4461, Valid: 0.3910, Test: 0.4406\n",
            "Fold: 1, Epoch: 011, Train: 0.6434, Valid: 0.6441, Test: 0.6261\n",
            "Fold: 1, Epoch: 021, Train: 0.7359, Valid: 0.7343, Test: 0.7402\n",
            "Fold: 1, Epoch: 031, Train: 0.7545, Valid: 0.7444, Test: 0.7603\n",
            "Fold: 1, Epoch: 041, Train: 0.8208, Valid: 0.8271, Test: 0.8282\n",
            "Fold: 2, Epoch: 001, Train: 0.8626, Valid: 0.8521, Test: 0.8561\n",
            "Fold: 2, Epoch: 011, Train: 0.8805, Valid: 0.8596, Test: 0.8741\n",
            "Fold: 2, Epoch: 021, Train: 0.8863, Valid: 0.8496, Test: 0.8847\n",
            "Fold: 2, Epoch: 031, Train: 0.8947, Valid: 0.8672, Test: 0.8934\n",
            "Fold: 2, Epoch: 041, Train: 0.9016, Valid: 0.8596, Test: 0.8949\n",
            "Fold: 3, Epoch: 001, Train: 0.9081, Valid: 0.8772, Test: 0.9087\n",
            "Fold: 3, Epoch: 011, Train: 0.9189, Valid: 0.8747, Test: 0.9193\n",
            "Fold: 3, Epoch: 021, Train: 0.9195, Valid: 0.8922, Test: 0.9142\n",
            "Fold: 3, Epoch: 031, Train: 0.9225, Valid: 0.8897, Test: 0.9183\n",
            "Fold: 3, Epoch: 041, Train: 0.9351, Valid: 0.8872, Test: 0.9288\n",
            "Fold: 4, Epoch: 001, Train: 0.9292, Valid: 0.9398, Test: 0.9323\n",
            "Fold: 4, Epoch: 011, Train: 0.9262, Valid: 0.9373, Test: 0.9265\n",
            "Fold: 4, Epoch: 021, Train: 0.9381, Valid: 0.9524, Test: 0.9366\n",
            "Fold: 4, Epoch: 031, Train: 0.9337, Valid: 0.9424, Test: 0.9363\n",
            "Fold: 4, Epoch: 041, Train: 0.9348, Valid: 0.9323, Test: 0.9303\n",
            "Fold: 5, Epoch: 001, Train: 0.9420, Valid: 0.9524, Test: 0.9438\n",
            "Fold: 5, Epoch: 011, Train: 0.9521, Valid: 0.9549, Test: 0.9471\n",
            "Fold: 5, Epoch: 021, Train: 0.9471, Valid: 0.9499, Test: 0.9501\n",
            "Fold: 5, Epoch: 031, Train: 0.9546, Valid: 0.9348, Test: 0.9539\n",
            "Fold: 5, Epoch: 041, Train: 0.9554, Valid: 0.9449, Test: 0.9549\n",
            "Fold: 6, Epoch: 001, Train: 0.9420, Valid: 0.9323, Test: 0.9376\n",
            "Fold: 6, Epoch: 011, Train: 0.9543, Valid: 0.9398, Test: 0.9576\n",
            "Fold: 6, Epoch: 021, Train: 0.9482, Valid: 0.9273, Test: 0.9456\n",
            "Fold: 6, Epoch: 031, Train: 0.9571, Valid: 0.9373, Test: 0.9556\n",
            "Fold: 6, Epoch: 041, Train: 0.9557, Valid: 0.9273, Test: 0.9509\n",
            "Fold: 7, Epoch: 001, Train: 0.9593, Valid: 0.9624, Test: 0.9609\n",
            "Fold: 7, Epoch: 011, Train: 0.9596, Valid: 0.9574, Test: 0.9601\n",
            "Fold: 7, Epoch: 021, Train: 0.9660, Valid: 0.9549, Test: 0.9646\n",
            "Fold: 7, Epoch: 031, Train: 0.9654, Valid: 0.9574, Test: 0.9674\n",
            "Fold: 7, Epoch: 041, Train: 0.9680, Valid: 0.9649, Test: 0.9679\n",
            "Fold: 8, Epoch: 001, Train: 0.9671, Valid: 0.9649, Test: 0.9661\n",
            "Fold: 8, Epoch: 011, Train: 0.9663, Valid: 0.9674, Test: 0.9692\n",
            "Fold: 8, Epoch: 021, Train: 0.9707, Valid: 0.9649, Test: 0.9717\n",
            "Fold: 8, Epoch: 031, Train: 0.9688, Valid: 0.9574, Test: 0.9641\n",
            "Fold: 8, Epoch: 041, Train: 0.9730, Valid: 0.9574, Test: 0.9722\n",
            "Fold: 9, Epoch: 001, Train: 0.9669, Valid: 0.9673, Test: 0.9661\n",
            "Fold: 9, Epoch: 011, Train: 0.9735, Valid: 0.9673, Test: 0.9727\n",
            "Fold: 9, Epoch: 021, Train: 0.9760, Valid: 0.9598, Test: 0.9754\n",
            "Fold: 9, Epoch: 031, Train: 0.9772, Valid: 0.9648, Test: 0.9749\n",
            "Fold: 9, Epoch: 041, Train: 0.9777, Valid: 0.9523, Test: 0.9752\n",
            "Fold: 10, Epoch: 001, Train: 0.9747, Valid: 0.9698, Test: 0.9757\n",
            "Fold: 10, Epoch: 011, Train: 0.9688, Valid: 0.9623, Test: 0.9704\n",
            "Fold: 10, Epoch: 021, Train: 0.9602, Valid: 0.9472, Test: 0.9561\n",
            "Fold: 10, Epoch: 031, Train: 0.9783, Valid: 0.9573, Test: 0.9739\n",
            "Fold: 10, Epoch: 041, Train: 0.9802, Valid: 0.9724, Test: 0.9789\n",
            "\n",
            "Elapsed Time:  1036.2185397148132\n"
          ]
        }
      ],
      "source": [
        "main('SAGE', dataset_graph, test_graph, model_dir, result_dir, k_hop=3, k_fold=10, n_epo=50)"
      ],
      "id": "b5219c00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91a7b00b",
        "outputId": "94261085-ecbc-4ab0-954b-396483ecd5c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4999, Valid: 0.5238, Test: 0.4920\n",
            "Fold: 1, Epoch: 011, Train: 0.7099, Valid: 0.7168, Test: 0.7121\n",
            "Fold: 1, Epoch: 021, Train: 0.7283, Valid: 0.7544, Test: 0.7309\n",
            "Fold: 1, Epoch: 031, Train: 0.8041, Valid: 0.8271, Test: 0.8087\n",
            "Fold: 1, Epoch: 041, Train: 0.8437, Valid: 0.8596, Test: 0.8410\n",
            "Fold: 2, Epoch: 001, Train: 0.8468, Valid: 0.8521, Test: 0.8460\n",
            "Fold: 2, Epoch: 011, Train: 0.8766, Valid: 0.8747, Test: 0.8774\n",
            "Fold: 2, Epoch: 021, Train: 0.8899, Valid: 0.8897, Test: 0.8947\n",
            "Fold: 2, Epoch: 031, Train: 0.8989, Valid: 0.8997, Test: 0.8952\n",
            "Fold: 2, Epoch: 041, Train: 0.9089, Valid: 0.8972, Test: 0.9087\n",
            "Fold: 3, Epoch: 001, Train: 0.9145, Valid: 0.9198, Test: 0.9155\n",
            "Fold: 3, Epoch: 011, Train: 0.9178, Valid: 0.9198, Test: 0.9188\n",
            "Fold: 3, Epoch: 021, Train: 0.9209, Valid: 0.9273, Test: 0.9208\n",
            "Fold: 3, Epoch: 031, Train: 0.9326, Valid: 0.9148, Test: 0.9275\n",
            "Fold: 3, Epoch: 041, Train: 0.9351, Valid: 0.9248, Test: 0.9338\n",
            "Fold: 4, Epoch: 001, Train: 0.9348, Valid: 0.9373, Test: 0.9351\n",
            "Fold: 4, Epoch: 011, Train: 0.9323, Valid: 0.9248, Test: 0.9348\n",
            "Fold: 4, Epoch: 021, Train: 0.9387, Valid: 0.9323, Test: 0.9386\n",
            "Fold: 4, Epoch: 031, Train: 0.9429, Valid: 0.9323, Test: 0.9383\n",
            "Fold: 4, Epoch: 041, Train: 0.9521, Valid: 0.9298, Test: 0.9501\n",
            "Fold: 5, Epoch: 001, Train: 0.9518, Valid: 0.9724, Test: 0.9521\n",
            "Fold: 5, Epoch: 011, Train: 0.9568, Valid: 0.9674, Test: 0.9549\n",
            "Fold: 5, Epoch: 021, Train: 0.9568, Valid: 0.9624, Test: 0.9589\n",
            "Fold: 5, Epoch: 031, Train: 0.9599, Valid: 0.9599, Test: 0.9589\n",
            "Fold: 5, Epoch: 041, Train: 0.9613, Valid: 0.9624, Test: 0.9619\n",
            "Fold: 6, Epoch: 001, Train: 0.9643, Valid: 0.9599, Test: 0.9611\n",
            "Fold: 6, Epoch: 011, Train: 0.9579, Valid: 0.9499, Test: 0.9546\n",
            "Fold: 6, Epoch: 021, Train: 0.9691, Valid: 0.9474, Test: 0.9654\n",
            "Fold: 6, Epoch: 031, Train: 0.9668, Valid: 0.9549, Test: 0.9634\n",
            "Fold: 6, Epoch: 041, Train: 0.9680, Valid: 0.9524, Test: 0.9672\n",
            "Fold: 7, Epoch: 001, Train: 0.9727, Valid: 0.9749, Test: 0.9722\n",
            "Fold: 7, Epoch: 011, Train: 0.9741, Valid: 0.9699, Test: 0.9724\n",
            "Fold: 7, Epoch: 021, Train: 0.9741, Valid: 0.9574, Test: 0.9709\n",
            "Fold: 7, Epoch: 031, Train: 0.9735, Valid: 0.9549, Test: 0.9709\n",
            "Fold: 7, Epoch: 041, Train: 0.9785, Valid: 0.9549, Test: 0.9729\n",
            "Fold: 8, Epoch: 001, Train: 0.9746, Valid: 0.9699, Test: 0.9752\n",
            "Fold: 8, Epoch: 011, Train: 0.9691, Valid: 0.9524, Test: 0.9669\n",
            "Fold: 8, Epoch: 021, Train: 0.9811, Valid: 0.9674, Test: 0.9787\n",
            "Fold: 8, Epoch: 031, Train: 0.9758, Valid: 0.9599, Test: 0.9714\n",
            "Fold: 8, Epoch: 041, Train: 0.9808, Valid: 0.9624, Test: 0.9779\n",
            "Fold: 9, Epoch: 001, Train: 0.9760, Valid: 0.9724, Test: 0.9722\n",
            "Fold: 9, Epoch: 011, Train: 0.9769, Valid: 0.9724, Test: 0.9767\n",
            "Fold: 9, Epoch: 021, Train: 0.9805, Valid: 0.9749, Test: 0.9797\n",
            "Fold: 9, Epoch: 031, Train: 0.9760, Valid: 0.9749, Test: 0.9759\n",
            "Fold: 9, Epoch: 041, Train: 0.9783, Valid: 0.9673, Test: 0.9772\n",
            "Fold: 10, Epoch: 001, Train: 0.9802, Valid: 0.9874, Test: 0.9819\n",
            "Fold: 10, Epoch: 011, Train: 0.9855, Valid: 0.9824, Test: 0.9852\n",
            "Fold: 10, Epoch: 021, Train: 0.9866, Valid: 0.9849, Test: 0.9829\n",
            "Fold: 10, Epoch: 031, Train: 0.9847, Valid: 0.9774, Test: 0.9827\n",
            "Fold: 10, Epoch: 041, Train: 0.9805, Valid: 0.9724, Test: 0.9784\n",
            "\n",
            "Elapsed Time:  1308.9043390750885\n"
          ]
        }
      ],
      "source": [
        "main('SAGE', dataset_graph, test_graph, model_dir, result_dir, k_hop=4, k_fold=10, n_epo=50)"
      ],
      "id": "91a7b00b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O01msRm1uh2",
        "outputId": "dcec4ef3-0649-45a6-d77f-883c1442a939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.5272, Valid: 0.5414, Test: 0.5306\n",
            "Fold: 1, Epoch: 011, Train: 0.6991, Valid: 0.7218, Test: 0.7009\n",
            "Fold: 1, Epoch: 021, Train: 0.7492, Valid: 0.7569, Test: 0.7550\n",
            "Fold: 1, Epoch: 031, Train: 0.7751, Valid: 0.7820, Test: 0.7791\n",
            "Fold: 1, Epoch: 041, Train: 0.8247, Valid: 0.8221, Test: 0.8260\n",
            "Fold: 2, Epoch: 001, Train: 0.8417, Valid: 0.8396, Test: 0.8430\n",
            "Fold: 2, Epoch: 011, Train: 0.8649, Valid: 0.8546, Test: 0.8586\n",
            "Fold: 2, Epoch: 021, Train: 0.8819, Valid: 0.8546, Test: 0.8756\n",
            "Fold: 2, Epoch: 031, Train: 0.8997, Valid: 0.8947, Test: 0.9012\n",
            "Fold: 2, Epoch: 041, Train: 0.9089, Valid: 0.9123, Test: 0.9107\n",
            "Fold: 3, Epoch: 001, Train: 0.9170, Valid: 0.8997, Test: 0.9132\n",
            "Fold: 3, Epoch: 011, Train: 0.9245, Valid: 0.8897, Test: 0.9175\n",
            "Fold: 3, Epoch: 021, Train: 0.9284, Valid: 0.8972, Test: 0.9228\n",
            "Fold: 3, Epoch: 031, Train: 0.9245, Valid: 0.8972, Test: 0.9203\n",
            "Fold: 3, Epoch: 041, Train: 0.9250, Valid: 0.8897, Test: 0.9185\n",
            "Fold: 4, Epoch: 001, Train: 0.9287, Valid: 0.9173, Test: 0.9275\n",
            "Fold: 4, Epoch: 011, Train: 0.9334, Valid: 0.9173, Test: 0.9358\n",
            "Fold: 4, Epoch: 021, Train: 0.9348, Valid: 0.9148, Test: 0.9328\n",
            "Fold: 4, Epoch: 031, Train: 0.9401, Valid: 0.9273, Test: 0.9356\n",
            "Fold: 4, Epoch: 041, Train: 0.9440, Valid: 0.9148, Test: 0.9421\n",
            "Fold: 5, Epoch: 001, Train: 0.9395, Valid: 0.9674, Test: 0.9433\n",
            "Fold: 5, Epoch: 011, Train: 0.9409, Valid: 0.9499, Test: 0.9428\n",
            "Fold: 5, Epoch: 021, Train: 0.9457, Valid: 0.9574, Test: 0.9473\n",
            "Fold: 5, Epoch: 031, Train: 0.9535, Valid: 0.9574, Test: 0.9534\n",
            "Fold: 5, Epoch: 041, Train: 0.9409, Valid: 0.9499, Test: 0.9458\n",
            "Fold: 6, Epoch: 001, Train: 0.9448, Valid: 0.9574, Test: 0.9488\n",
            "Fold: 6, Epoch: 011, Train: 0.9576, Valid: 0.9624, Test: 0.9544\n",
            "Fold: 6, Epoch: 021, Train: 0.9582, Valid: 0.9549, Test: 0.9554\n",
            "Fold: 6, Epoch: 031, Train: 0.9582, Valid: 0.9574, Test: 0.9589\n",
            "Fold: 6, Epoch: 041, Train: 0.9604, Valid: 0.9624, Test: 0.9611\n",
            "Fold: 7, Epoch: 001, Train: 0.9618, Valid: 0.9474, Test: 0.9589\n",
            "Fold: 7, Epoch: 011, Train: 0.9710, Valid: 0.9499, Test: 0.9682\n",
            "Fold: 7, Epoch: 021, Train: 0.9738, Valid: 0.9499, Test: 0.9689\n",
            "Fold: 7, Epoch: 031, Train: 0.9769, Valid: 0.9398, Test: 0.9739\n",
            "Fold: 7, Epoch: 041, Train: 0.9663, Valid: 0.9398, Test: 0.9624\n",
            "Fold: 8, Epoch: 001, Train: 0.9654, Valid: 0.9574, Test: 0.9626\n",
            "Fold: 8, Epoch: 011, Train: 0.9741, Valid: 0.9749, Test: 0.9752\n",
            "Fold: 8, Epoch: 021, Train: 0.9744, Valid: 0.9599, Test: 0.9707\n",
            "Fold: 8, Epoch: 031, Train: 0.9719, Valid: 0.9524, Test: 0.9689\n",
            "Fold: 8, Epoch: 041, Train: 0.9799, Valid: 0.9549, Test: 0.9774\n",
            "Fold: 9, Epoch: 001, Train: 0.9788, Valid: 0.9874, Test: 0.9794\n",
            "Fold: 9, Epoch: 011, Train: 0.9799, Valid: 0.9774, Test: 0.9807\n",
            "Fold: 9, Epoch: 021, Train: 0.9855, Valid: 0.9623, Test: 0.9835\n",
            "Fold: 9, Epoch: 031, Train: 0.9841, Valid: 0.9724, Test: 0.9827\n",
            "Fold: 9, Epoch: 041, Train: 0.9682, Valid: 0.9749, Test: 0.9677\n",
            "Fold: 10, Epoch: 001, Train: 0.9872, Valid: 0.9824, Test: 0.9845\n",
            "Fold: 10, Epoch: 011, Train: 0.9791, Valid: 0.9698, Test: 0.9784\n",
            "Fold: 10, Epoch: 021, Train: 0.9786, Valid: 0.9774, Test: 0.9792\n",
            "Fold: 10, Epoch: 031, Train: 0.9822, Valid: 0.9548, Test: 0.9779\n",
            "Fold: 10, Epoch: 041, Train: 0.9852, Valid: 0.9623, Test: 0.9807\n",
            "\n",
            "Elapsed Time:  1622.451521396637\n"
          ]
        }
      ],
      "source": [
        "main('SAGE', dataset_graph, test_graph, model_dir, result_dir, k_hop=5, k_fold=10, n_epo=50)"
      ],
      "id": "_O01msRm1uh2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV10v3IV1wOH",
        "outputId": "62536c56-03f1-4a25-bfe8-de8c7b09f230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.5517, Valid: 0.5739, Test: 0.5429\n",
            "Fold: 1, Epoch: 011, Train: 0.7373, Valid: 0.7444, Test: 0.7390\n",
            "Fold: 1, Epoch: 021, Train: 0.7885, Valid: 0.7744, Test: 0.7849\n",
            "Fold: 1, Epoch: 031, Train: 0.8548, Valid: 0.8296, Test: 0.8581\n",
            "Fold: 1, Epoch: 041, Train: 0.8872, Valid: 0.8697, Test: 0.8879\n",
            "Fold: 2, Epoch: 001, Train: 0.8980, Valid: 0.9248, Test: 0.9012\n",
            "Fold: 2, Epoch: 011, Train: 0.9050, Valid: 0.9198, Test: 0.9115\n",
            "Fold: 2, Epoch: 021, Train: 0.9309, Valid: 0.9449, Test: 0.9330\n",
            "Fold: 2, Epoch: 031, Train: 0.9329, Valid: 0.9398, Test: 0.9333\n",
            "Fold: 2, Epoch: 041, Train: 0.9379, Valid: 0.9373, Test: 0.9406\n",
            "Fold: 3, Epoch: 001, Train: 0.8069, Valid: 0.8120, Test: 0.8047\n",
            "Fold: 3, Epoch: 011, Train: 0.9504, Valid: 0.9223, Test: 0.9473\n",
            "Fold: 3, Epoch: 021, Train: 0.9574, Valid: 0.9398, Test: 0.9544\n",
            "Fold: 3, Epoch: 031, Train: 0.9479, Valid: 0.9173, Test: 0.9463\n",
            "Fold: 3, Epoch: 041, Train: 0.9688, Valid: 0.9223, Test: 0.9631\n",
            "Fold: 4, Epoch: 001, Train: 0.9685, Valid: 0.9724, Test: 0.9697\n",
            "Fold: 4, Epoch: 011, Train: 0.9685, Valid: 0.9624, Test: 0.9672\n",
            "Fold: 4, Epoch: 021, Train: 0.9590, Valid: 0.9449, Test: 0.9534\n",
            "Fold: 4, Epoch: 031, Train: 0.9724, Valid: 0.9649, Test: 0.9719\n",
            "Fold: 4, Epoch: 041, Train: 0.9702, Valid: 0.9599, Test: 0.9679\n",
            "Fold: 5, Epoch: 001, Train: 0.9677, Valid: 0.9724, Test: 0.9672\n",
            "Fold: 5, Epoch: 011, Train: 0.9752, Valid: 0.9724, Test: 0.9767\n",
            "Fold: 5, Epoch: 021, Train: 0.9524, Valid: 0.9424, Test: 0.9519\n",
            "Fold: 5, Epoch: 031, Train: 0.9512, Valid: 0.9298, Test: 0.9478\n",
            "Fold: 5, Epoch: 041, Train: 0.9738, Valid: 0.9649, Test: 0.9707\n",
            "Fold: 6, Epoch: 001, Train: 0.9785, Valid: 0.9925, Test: 0.9807\n",
            "Fold: 6, Epoch: 011, Train: 0.9866, Valid: 0.9850, Test: 0.9860\n",
            "Fold: 6, Epoch: 021, Train: 0.9763, Valid: 0.9749, Test: 0.9792\n",
            "Fold: 6, Epoch: 031, Train: 0.9880, Valid: 0.9649, Test: 0.9852\n",
            "Fold: 6, Epoch: 041, Train: 0.9844, Valid: 0.9774, Test: 0.9847\n",
            "Fold: 7, Epoch: 001, Train: 0.9794, Valid: 0.9799, Test: 0.9774\n",
            "Fold: 7, Epoch: 011, Train: 0.9872, Valid: 0.9850, Test: 0.9855\n",
            "Fold: 7, Epoch: 021, Train: 0.9861, Valid: 0.9624, Test: 0.9845\n",
            "Fold: 7, Epoch: 031, Train: 0.9905, Valid: 0.9724, Test: 0.9885\n",
            "Fold: 7, Epoch: 041, Train: 0.9883, Valid: 0.9649, Test: 0.9872\n",
            "Fold: 8, Epoch: 001, Train: 0.9691, Valid: 0.9724, Test: 0.9674\n",
            "Fold: 8, Epoch: 011, Train: 0.9780, Valid: 0.9699, Test: 0.9759\n",
            "Fold: 8, Epoch: 021, Train: 0.9955, Valid: 0.9850, Test: 0.9912\n",
            "Fold: 8, Epoch: 031, Train: 0.9944, Valid: 0.9825, Test: 0.9920\n",
            "Fold: 8, Epoch: 041, Train: 0.9758, Valid: 0.9649, Test: 0.9759\n",
            "Fold: 9, Epoch: 001, Train: 0.9911, Valid: 0.9849, Test: 0.9897\n",
            "Fold: 9, Epoch: 011, Train: 0.9939, Valid: 0.9849, Test: 0.9937\n",
            "Fold: 9, Epoch: 021, Train: 0.9969, Valid: 0.9925, Test: 0.9937\n",
            "Fold: 9, Epoch: 031, Train: 0.9936, Valid: 0.9849, Test: 0.9925\n",
            "Fold: 9, Epoch: 041, Train: 0.9953, Valid: 0.9874, Test: 0.9942\n",
            "Fold: 10, Epoch: 001, Train: 0.9919, Valid: 0.9925, Test: 0.9912\n",
            "Fold: 10, Epoch: 011, Train: 0.9894, Valid: 0.9824, Test: 0.9905\n",
            "Fold: 10, Epoch: 021, Train: 0.9877, Valid: 0.9824, Test: 0.9875\n",
            "Fold: 10, Epoch: 031, Train: 0.9911, Valid: 0.9698, Test: 0.9892\n",
            "Fold: 10, Epoch: 041, Train: 0.9983, Valid: 0.9849, Test: 0.9955\n",
            "\n",
            "Elapsed Time:  1867.026662826538\n"
          ]
        }
      ],
      "source": [
        "main('SAGE', dataset_graph, test_graph, model_dir, result_dir, k_hop=6, k_fold=10, n_epo=50)"
      ],
      "id": "kV10v3IV1wOH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPtoHnYm1xn_",
        "outputId": "c088efb4-396b-4e89-fdb0-4174e6b170ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.5472, Valid: 0.5414, Test: 0.5527\n",
            "Fold: 1, Epoch: 011, Train: 0.7478, Valid: 0.7218, Test: 0.7395\n",
            "Fold: 1, Epoch: 021, Train: 0.7788, Valid: 0.7519, Test: 0.7788\n",
            "Fold: 1, Epoch: 031, Train: 0.7896, Valid: 0.7594, Test: 0.7849\n",
            "Fold: 1, Epoch: 041, Train: 0.8286, Valid: 0.8070, Test: 0.8277\n",
            "Fold: 2, Epoch: 001, Train: 0.7894, Valid: 0.7794, Test: 0.7921\n",
            "Fold: 2, Epoch: 011, Train: 0.8866, Valid: 0.8647, Test: 0.8811\n",
            "Fold: 2, Epoch: 021, Train: 0.8902, Valid: 0.8622, Test: 0.8892\n",
            "Fold: 2, Epoch: 031, Train: 0.9075, Valid: 0.8747, Test: 0.9012\n",
            "Fold: 2, Epoch: 041, Train: 0.9047, Valid: 0.8797, Test: 0.9030\n",
            "Fold: 3, Epoch: 001, Train: 0.9145, Valid: 0.9273, Test: 0.9165\n",
            "Fold: 3, Epoch: 011, Train: 0.9303, Valid: 0.9248, Test: 0.9305\n",
            "Fold: 3, Epoch: 021, Train: 0.9356, Valid: 0.9198, Test: 0.9343\n",
            "Fold: 3, Epoch: 031, Train: 0.9234, Valid: 0.9223, Test: 0.9268\n",
            "Fold: 3, Epoch: 041, Train: 0.9432, Valid: 0.9323, Test: 0.9403\n",
            "Fold: 4, Epoch: 001, Train: 0.9473, Valid: 0.9449, Test: 0.9436\n",
            "Fold: 4, Epoch: 011, Train: 0.9462, Valid: 0.9424, Test: 0.9441\n",
            "Fold: 4, Epoch: 021, Train: 0.9526, Valid: 0.9398, Test: 0.9519\n",
            "Fold: 4, Epoch: 031, Train: 0.9557, Valid: 0.9449, Test: 0.9529\n",
            "Fold: 4, Epoch: 041, Train: 0.9604, Valid: 0.9449, Test: 0.9594\n",
            "Fold: 5, Epoch: 001, Train: 0.9574, Valid: 0.9549, Test: 0.9574\n",
            "Fold: 5, Epoch: 011, Train: 0.9568, Valid: 0.9398, Test: 0.9576\n",
            "Fold: 5, Epoch: 021, Train: 0.9604, Valid: 0.9449, Test: 0.9611\n",
            "Fold: 5, Epoch: 031, Train: 0.9705, Valid: 0.9424, Test: 0.9644\n",
            "Fold: 5, Epoch: 041, Train: 0.9546, Valid: 0.9248, Test: 0.9504\n",
            "Fold: 6, Epoch: 001, Train: 0.9685, Valid: 0.9799, Test: 0.9687\n",
            "Fold: 6, Epoch: 011, Train: 0.9663, Valid: 0.9699, Test: 0.9672\n",
            "Fold: 6, Epoch: 021, Train: 0.9733, Valid: 0.9674, Test: 0.9727\n",
            "Fold: 6, Epoch: 031, Train: 0.9763, Valid: 0.9599, Test: 0.9742\n",
            "Fold: 6, Epoch: 041, Train: 0.9766, Valid: 0.9649, Test: 0.9747\n",
            "Fold: 7, Epoch: 001, Train: 0.9724, Valid: 0.9900, Test: 0.9732\n",
            "Fold: 7, Epoch: 011, Train: 0.9744, Valid: 0.9850, Test: 0.9764\n",
            "Fold: 7, Epoch: 021, Train: 0.9799, Valid: 0.9799, Test: 0.9794\n",
            "Fold: 7, Epoch: 031, Train: 0.9808, Valid: 0.9724, Test: 0.9799\n",
            "Fold: 7, Epoch: 041, Train: 0.9802, Valid: 0.9774, Test: 0.9819\n",
            "Fold: 8, Epoch: 001, Train: 0.9794, Valid: 0.9699, Test: 0.9799\n",
            "Fold: 8, Epoch: 011, Train: 0.9799, Valid: 0.9674, Test: 0.9784\n",
            "Fold: 8, Epoch: 021, Train: 0.9724, Valid: 0.9599, Test: 0.9724\n",
            "Fold: 8, Epoch: 031, Train: 0.9785, Valid: 0.9674, Test: 0.9807\n",
            "Fold: 8, Epoch: 041, Train: 0.9805, Valid: 0.9574, Test: 0.9779\n",
            "Fold: 9, Epoch: 001, Train: 0.9836, Valid: 0.9749, Test: 0.9837\n",
            "Fold: 9, Epoch: 011, Train: 0.9811, Valid: 0.9724, Test: 0.9819\n",
            "Fold: 9, Epoch: 021, Train: 0.9822, Valid: 0.9548, Test: 0.9784\n",
            "Fold: 9, Epoch: 031, Train: 0.9844, Valid: 0.9422, Test: 0.9804\n",
            "Fold: 9, Epoch: 041, Train: 0.9760, Valid: 0.9573, Test: 0.9754\n",
            "Fold: 10, Epoch: 001, Train: 0.9769, Valid: 0.9799, Test: 0.9764\n",
            "Fold: 10, Epoch: 011, Train: 0.9799, Valid: 0.9774, Test: 0.9802\n",
            "Fold: 10, Epoch: 021, Train: 0.9852, Valid: 0.9849, Test: 0.9845\n",
            "Fold: 10, Epoch: 031, Train: 0.9847, Valid: 0.9799, Test: 0.9842\n",
            "Fold: 10, Epoch: 041, Train: 0.9858, Valid: 0.9724, Test: 0.9845\n",
            "\n",
            "Elapsed Time:  2143.977549791336\n"
          ]
        }
      ],
      "source": [
        "main('SAGE', dataset_graph, test_graph, model_dir, result_dir, k_hop=7, k_fold=10, n_epo=50)"
      ],
      "id": "kPtoHnYm1xn_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eivOC3uU1zZP",
        "outputId": "bd30c713-22b4-482b-802e-0079f50a36d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.5394, Valid: 0.5539, Test: 0.5436\n",
            "Fold: 1, Epoch: 011, Train: 0.7905, Valid: 0.7845, Test: 0.7886\n",
            "Fold: 1, Epoch: 021, Train: 0.8103, Valid: 0.8070, Test: 0.8094\n",
            "Fold: 1, Epoch: 031, Train: 0.8390, Valid: 0.8195, Test: 0.8383\n",
            "Fold: 1, Epoch: 041, Train: 0.8724, Valid: 0.8596, Test: 0.8643\n",
            "Fold: 2, Epoch: 001, Train: 0.9030, Valid: 0.9073, Test: 0.9032\n",
            "Fold: 2, Epoch: 011, Train: 0.9206, Valid: 0.8972, Test: 0.9215\n",
            "Fold: 2, Epoch: 021, Train: 0.9117, Valid: 0.9123, Test: 0.9112\n",
            "Fold: 2, Epoch: 031, Train: 0.9211, Valid: 0.9223, Test: 0.9198\n",
            "Fold: 2, Epoch: 041, Train: 0.9376, Valid: 0.9248, Test: 0.9341\n",
            "Fold: 3, Epoch: 001, Train: 0.9379, Valid: 0.9398, Test: 0.9406\n",
            "Fold: 3, Epoch: 011, Train: 0.9390, Valid: 0.9373, Test: 0.9366\n",
            "Fold: 3, Epoch: 021, Train: 0.9487, Valid: 0.9373, Test: 0.9483\n",
            "Fold: 3, Epoch: 031, Train: 0.9493, Valid: 0.9424, Test: 0.9483\n",
            "Fold: 3, Epoch: 041, Train: 0.9635, Valid: 0.9574, Test: 0.9596\n",
            "Fold: 4, Epoch: 001, Train: 0.9607, Valid: 0.9649, Test: 0.9616\n",
            "Fold: 4, Epoch: 011, Train: 0.9526, Valid: 0.9474, Test: 0.9539\n",
            "Fold: 4, Epoch: 021, Train: 0.9512, Valid: 0.9323, Test: 0.9516\n",
            "Fold: 4, Epoch: 031, Train: 0.9688, Valid: 0.9599, Test: 0.9694\n",
            "Fold: 4, Epoch: 041, Train: 0.9760, Valid: 0.9574, Test: 0.9742\n",
            "Fold: 5, Epoch: 001, Train: 0.9629, Valid: 0.9724, Test: 0.9601\n",
            "Fold: 5, Epoch: 011, Train: 0.9641, Valid: 0.9724, Test: 0.9659\n",
            "Fold: 5, Epoch: 021, Train: 0.9699, Valid: 0.9799, Test: 0.9714\n",
            "Fold: 5, Epoch: 031, Train: 0.9674, Valid: 0.9749, Test: 0.9677\n",
            "Fold: 5, Epoch: 041, Train: 0.9621, Valid: 0.9724, Test: 0.9599\n",
            "Fold: 6, Epoch: 001, Train: 0.9850, Valid: 0.9749, Test: 0.9840\n",
            "Fold: 6, Epoch: 011, Train: 0.9223, Valid: 0.8997, Test: 0.9210\n",
            "Fold: 6, Epoch: 021, Train: 0.9872, Valid: 0.9749, Test: 0.9865\n",
            "Fold: 6, Epoch: 031, Train: 0.9930, Valid: 0.9774, Test: 0.9902\n",
            "Fold: 6, Epoch: 041, Train: 0.9941, Valid: 0.9724, Test: 0.9912\n",
            "Fold: 7, Epoch: 001, Train: 0.9930, Valid: 0.9875, Test: 0.9942\n",
            "Fold: 7, Epoch: 011, Train: 0.9941, Valid: 0.9875, Test: 0.9945\n",
            "Fold: 7, Epoch: 021, Train: 0.9273, Valid: 0.9198, Test: 0.9265\n",
            "Fold: 7, Epoch: 031, Train: 0.9964, Valid: 0.9774, Test: 0.9950\n",
            "Fold: 7, Epoch: 041, Train: 0.9791, Valid: 0.9599, Test: 0.9777\n",
            "Fold: 8, Epoch: 001, Train: 0.9919, Valid: 0.9900, Test: 0.9915\n",
            "Fold: 8, Epoch: 011, Train: 0.9964, Valid: 0.9975, Test: 0.9952\n",
            "Fold: 8, Epoch: 021, Train: 0.9964, Valid: 0.9975, Test: 0.9975\n",
            "Fold: 8, Epoch: 031, Train: 0.9992, Valid: 0.9900, Test: 0.9985\n",
            "Fold: 8, Epoch: 041, Train: 0.9967, Valid: 0.9850, Test: 0.9962\n",
            "Fold: 9, Epoch: 001, Train: 0.9682, Valid: 0.9648, Test: 0.9672\n",
            "Fold: 9, Epoch: 011, Train: 0.9958, Valid: 0.9950, Test: 0.9960\n",
            "Fold: 9, Epoch: 021, Train: 0.9994, Valid: 0.9950, Test: 0.9990\n",
            "Fold: 9, Epoch: 031, Train: 0.9950, Valid: 0.9899, Test: 0.9937\n",
            "Fold: 9, Epoch: 041, Train: 0.9997, Valid: 0.9975, Test: 0.9995\n",
            "Fold: 10, Epoch: 001, Train: 0.8914, Valid: 0.9045, Test: 0.8927\n",
            "Fold: 10, Epoch: 011, Train: 0.9992, Valid: 1.0000, Test: 0.9992\n",
            "Fold: 10, Epoch: 021, Train: 0.9997, Valid: 0.9975, Test: 1.0000\n",
            "Fold: 10, Epoch: 031, Train: 0.9997, Valid: 1.0000, Test: 1.0000\n",
            "Fold: 10, Epoch: 041, Train: 1.0000, Valid: 1.0000, Test: 1.0000\n",
            "\n",
            "Elapsed Time:  2451.6030852794647\n"
          ]
        }
      ],
      "source": [
        "main('SAGE', dataset_graph, test_graph, model_dir, result_dir, k_hop=8, k_fold=10, n_epo=50)"
      ],
      "id": "eivOC3uU1zZP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYTDA1wh1zTX",
        "outputId": "5d56f262-faac-4cae-94a4-1beaeee3486d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4990, Valid: 0.5138, Test: 0.4960\n",
            "Fold: 1, Epoch: 011, Train: 0.7214, Valid: 0.7018, Test: 0.7227\n",
            "Fold: 1, Epoch: 021, Train: 0.7852, Valid: 0.7694, Test: 0.7766\n",
            "Fold: 1, Epoch: 031, Train: 0.7802, Valid: 0.7619, Test: 0.7839\n",
            "Fold: 1, Epoch: 041, Train: 0.8194, Valid: 0.8271, Test: 0.8222\n",
            "Fold: 2, Epoch: 001, Train: 0.8459, Valid: 0.8747, Test: 0.8490\n",
            "Fold: 2, Epoch: 011, Train: 0.8532, Valid: 0.8822, Test: 0.8581\n",
            "Fold: 2, Epoch: 021, Train: 0.8716, Valid: 0.8872, Test: 0.8719\n",
            "Fold: 2, Epoch: 031, Train: 0.8952, Valid: 0.9223, Test: 0.8927\n",
            "Fold: 2, Epoch: 041, Train: 0.9025, Valid: 0.9098, Test: 0.9010\n",
            "Fold: 3, Epoch: 001, Train: 0.9072, Valid: 0.8947, Test: 0.9075\n",
            "Fold: 3, Epoch: 011, Train: 0.9122, Valid: 0.9223, Test: 0.9127\n",
            "Fold: 3, Epoch: 021, Train: 0.9198, Valid: 0.8922, Test: 0.9183\n",
            "Fold: 3, Epoch: 031, Train: 0.9359, Valid: 0.8972, Test: 0.9328\n",
            "Fold: 3, Epoch: 041, Train: 0.9423, Valid: 0.9098, Test: 0.9386\n",
            "Fold: 4, Epoch: 001, Train: 0.9379, Valid: 0.9398, Test: 0.9343\n",
            "Fold: 4, Epoch: 011, Train: 0.9331, Valid: 0.9273, Test: 0.9361\n",
            "Fold: 4, Epoch: 021, Train: 0.9457, Valid: 0.9348, Test: 0.9423\n",
            "Fold: 4, Epoch: 031, Train: 0.9507, Valid: 0.9348, Test: 0.9504\n",
            "Fold: 4, Epoch: 041, Train: 0.9429, Valid: 0.9348, Test: 0.9418\n",
            "Fold: 5, Epoch: 001, Train: 0.9574, Valid: 0.9474, Test: 0.9541\n",
            "Fold: 5, Epoch: 011, Train: 0.9602, Valid: 0.9449, Test: 0.9554\n",
            "Fold: 5, Epoch: 021, Train: 0.9565, Valid: 0.9424, Test: 0.9584\n",
            "Fold: 5, Epoch: 031, Train: 0.9604, Valid: 0.9273, Test: 0.9569\n",
            "Fold: 5, Epoch: 041, Train: 0.9576, Valid: 0.9248, Test: 0.9531\n",
            "Fold: 6, Epoch: 001, Train: 0.9657, Valid: 0.9649, Test: 0.9656\n",
            "Fold: 6, Epoch: 011, Train: 0.9666, Valid: 0.9549, Test: 0.9674\n",
            "Fold: 6, Epoch: 021, Train: 0.9585, Valid: 0.9449, Test: 0.9571\n",
            "Fold: 6, Epoch: 031, Train: 0.9652, Valid: 0.9599, Test: 0.9619\n",
            "Fold: 6, Epoch: 041, Train: 0.9696, Valid: 0.9474, Test: 0.9684\n",
            "Fold: 7, Epoch: 001, Train: 0.9621, Valid: 0.9649, Test: 0.9616\n",
            "Fold: 7, Epoch: 011, Train: 0.9705, Valid: 0.9674, Test: 0.9704\n",
            "Fold: 7, Epoch: 021, Train: 0.9131, Valid: 0.9148, Test: 0.9115\n",
            "Fold: 7, Epoch: 031, Train: 0.9724, Valid: 0.9599, Test: 0.9699\n",
            "Fold: 7, Epoch: 041, Train: 0.9866, Valid: 0.9799, Test: 0.9867\n",
            "Fold: 8, Epoch: 001, Train: 0.9663, Valid: 0.9774, Test: 0.9659\n",
            "Fold: 8, Epoch: 011, Train: 0.9607, Valid: 0.9499, Test: 0.9584\n",
            "Fold: 8, Epoch: 021, Train: 0.9618, Valid: 0.9649, Test: 0.9651\n",
            "Fold: 8, Epoch: 031, Train: 0.9719, Valid: 0.9599, Test: 0.9694\n",
            "Fold: 8, Epoch: 041, Train: 0.9576, Valid: 0.9549, Test: 0.9579\n",
            "Fold: 9, Epoch: 001, Train: 0.9538, Valid: 0.9573, Test: 0.9536\n",
            "Fold: 9, Epoch: 011, Train: 0.9758, Valid: 0.9698, Test: 0.9744\n",
            "Fold: 9, Epoch: 021, Train: 0.9858, Valid: 0.9824, Test: 0.9857\n",
            "Fold: 9, Epoch: 031, Train: 0.9496, Valid: 0.9497, Test: 0.9521\n",
            "Fold: 9, Epoch: 041, Train: 0.9894, Valid: 0.9849, Test: 0.9895\n",
            "Fold: 10, Epoch: 001, Train: 0.9830, Valid: 0.9698, Test: 0.9822\n",
            "Fold: 10, Epoch: 011, Train: 0.9889, Valid: 0.9774, Test: 0.9887\n",
            "Fold: 10, Epoch: 021, Train: 0.9894, Valid: 0.9749, Test: 0.9875\n",
            "Fold: 10, Epoch: 031, Train: 0.9708, Valid: 0.9648, Test: 0.9689\n",
            "Fold: 10, Epoch: 041, Train: 0.9883, Valid: 0.9673, Test: 0.9824\n",
            "\n",
            "Elapsed Time:  2706.2172434329987\n"
          ]
        }
      ],
      "source": [
        "main('SAGE', dataset_graph, test_graph, model_dir, result_dir, k_hop=9, k_fold=10, n_epo=50)"
      ],
      "id": "FYTDA1wh1zTX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXBVvlQU119R",
        "outputId": "2cf81584-7299-4a74-fc9a-60b6b85c8b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.5578, Valid: 0.5739, Test: 0.5594\n",
            "Fold: 1, Epoch: 011, Train: 0.4670, Valid: 0.4536, Test: 0.4677\n",
            "Fold: 1, Epoch: 021, Train: 0.7924, Valid: 0.8020, Test: 0.7939\n",
            "Fold: 1, Epoch: 031, Train: 0.7370, Valid: 0.7093, Test: 0.7385\n",
            "Fold: 1, Epoch: 041, Train: 0.8398, Valid: 0.8246, Test: 0.8360\n",
            "Fold: 2, Epoch: 001, Train: 0.8632, Valid: 0.8647, Test: 0.8671\n",
            "Fold: 2, Epoch: 011, Train: 0.8919, Valid: 0.8797, Test: 0.8919\n",
            "Fold: 2, Epoch: 021, Train: 0.9061, Valid: 0.8897, Test: 0.9037\n",
            "Fold: 2, Epoch: 031, Train: 0.9136, Valid: 0.8797, Test: 0.9125\n",
            "Fold: 2, Epoch: 041, Train: 0.9248, Valid: 0.8922, Test: 0.9188\n",
            "Fold: 3, Epoch: 001, Train: 0.9234, Valid: 0.9223, Test: 0.9210\n",
            "Fold: 3, Epoch: 011, Train: 0.9298, Valid: 0.9123, Test: 0.9295\n",
            "Fold: 3, Epoch: 021, Train: 0.9292, Valid: 0.9148, Test: 0.9270\n",
            "Fold: 3, Epoch: 031, Train: 0.9384, Valid: 0.9173, Test: 0.9386\n",
            "Fold: 3, Epoch: 041, Train: 0.9462, Valid: 0.9223, Test: 0.9446\n",
            "Fold: 4, Epoch: 001, Train: 0.9320, Valid: 0.9323, Test: 0.9320\n",
            "Fold: 4, Epoch: 011, Train: 0.9446, Valid: 0.9449, Test: 0.9476\n",
            "Fold: 4, Epoch: 021, Train: 0.9498, Valid: 0.9348, Test: 0.9511\n",
            "Fold: 4, Epoch: 031, Train: 0.9331, Valid: 0.9273, Test: 0.9333\n",
            "Fold: 4, Epoch: 041, Train: 0.9565, Valid: 0.9398, Test: 0.9569\n",
            "Fold: 5, Epoch: 001, Train: 0.9571, Valid: 0.9549, Test: 0.9586\n",
            "Fold: 5, Epoch: 011, Train: 0.9568, Valid: 0.9549, Test: 0.9571\n",
            "Fold: 5, Epoch: 021, Train: 0.9680, Valid: 0.9499, Test: 0.9644\n",
            "Fold: 5, Epoch: 031, Train: 0.9510, Valid: 0.9348, Test: 0.9514\n",
            "Fold: 5, Epoch: 041, Train: 0.9760, Valid: 0.9524, Test: 0.9719\n",
            "Fold: 6, Epoch: 001, Train: 0.9482, Valid: 0.9599, Test: 0.9493\n",
            "Fold: 6, Epoch: 011, Train: 0.9724, Valid: 0.9724, Test: 0.9729\n",
            "Fold: 6, Epoch: 021, Train: 0.9763, Valid: 0.9574, Test: 0.9754\n",
            "Fold: 6, Epoch: 031, Train: 0.9267, Valid: 0.9424, Test: 0.9268\n",
            "Fold: 6, Epoch: 041, Train: 0.9774, Valid: 0.9624, Test: 0.9742\n",
            "Fold: 7, Epoch: 001, Train: 0.9741, Valid: 0.9774, Test: 0.9724\n",
            "Fold: 7, Epoch: 011, Train: 0.9797, Valid: 0.9799, Test: 0.9802\n",
            "Fold: 7, Epoch: 021, Train: 0.9794, Valid: 0.9799, Test: 0.9804\n",
            "Fold: 7, Epoch: 031, Train: 0.9827, Valid: 0.9699, Test: 0.9814\n",
            "Fold: 7, Epoch: 041, Train: 0.9816, Valid: 0.9674, Test: 0.9804\n",
            "Fold: 8, Epoch: 001, Train: 0.9822, Valid: 0.9799, Test: 0.9835\n",
            "Fold: 8, Epoch: 011, Train: 0.9869, Valid: 0.9774, Test: 0.9852\n",
            "Fold: 8, Epoch: 021, Train: 0.9850, Valid: 0.9674, Test: 0.9829\n",
            "Fold: 8, Epoch: 031, Train: 0.9822, Valid: 0.9649, Test: 0.9804\n",
            "Fold: 8, Epoch: 041, Train: 0.9861, Valid: 0.9649, Test: 0.9860\n",
            "Fold: 9, Epoch: 001, Train: 0.9702, Valid: 0.9749, Test: 0.9704\n",
            "Fold: 9, Epoch: 011, Train: 0.9613, Valid: 0.9648, Test: 0.9606\n",
            "Fold: 9, Epoch: 021, Train: 0.9891, Valid: 0.9749, Test: 0.9862\n",
            "Fold: 9, Epoch: 031, Train: 0.9891, Valid: 0.9749, Test: 0.9875\n",
            "Fold: 9, Epoch: 041, Train: 0.9886, Valid: 0.9749, Test: 0.9877\n",
            "Fold: 10, Epoch: 001, Train: 0.9674, Valid: 0.9698, Test: 0.9679\n",
            "Fold: 10, Epoch: 011, Train: 0.9699, Valid: 0.9648, Test: 0.9699\n",
            "Fold: 10, Epoch: 021, Train: 0.9916, Valid: 0.9925, Test: 0.9907\n",
            "Fold: 10, Epoch: 031, Train: 0.9933, Valid: 0.9749, Test: 0.9925\n",
            "Fold: 10, Epoch: 041, Train: 0.9961, Valid: 0.9749, Test: 0.9935\n",
            "\n",
            "Elapsed Time:  3068.7366771698\n"
          ]
        }
      ],
      "source": [
        "main('SAGE', dataset_graph, test_graph, model_dir, result_dir, k_hop=10, k_fold=10, n_epo=50)"
      ],
      "id": "LXBVvlQU119R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ac2a4b"
      },
      "source": [
        "## GCN Training with k = 1, 2, 3, 4"
      ],
      "id": "e1ac2a4b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "375bd1a0",
        "outputId": "53bd6919-5ea7-4e84-be1a-761e3a8bc308",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4466, Valid: 0.4361, Test: 0.4438\n",
            "Fold: 1, Epoch: 011, Train: 0.5068, Valid: 0.5138, Test: 0.5158\n",
            "Fold: 1, Epoch: 021, Train: 0.5559, Valid: 0.5815, Test: 0.5644\n",
            "Fold: 1, Epoch: 031, Train: 0.5592, Valid: 0.5714, Test: 0.5634\n",
            "Fold: 1, Epoch: 041, Train: 0.5626, Valid: 0.5890, Test: 0.5680\n",
            "Fold: 2, Epoch: 001, Train: 0.5706, Valid: 0.5865, Test: 0.5692\n",
            "Fold: 2, Epoch: 011, Train: 0.5804, Valid: 0.5990, Test: 0.5735\n",
            "Fold: 2, Epoch: 021, Train: 0.5765, Valid: 0.5940, Test: 0.5810\n",
            "Fold: 2, Epoch: 031, Train: 0.5779, Valid: 0.5865, Test: 0.5817\n",
            "Fold: 2, Epoch: 041, Train: 0.5782, Valid: 0.6015, Test: 0.5858\n",
            "Fold: 3, Epoch: 001, Train: 0.5910, Valid: 0.5915, Test: 0.5928\n",
            "Fold: 3, Epoch: 011, Train: 0.5846, Valid: 0.5940, Test: 0.5965\n",
            "Fold: 3, Epoch: 021, Train: 0.5971, Valid: 0.6115, Test: 0.5970\n",
            "Fold: 3, Epoch: 031, Train: 0.6030, Valid: 0.6115, Test: 0.6013\n",
            "Fold: 3, Epoch: 041, Train: 0.6010, Valid: 0.5990, Test: 0.6036\n",
            "Fold: 4, Epoch: 001, Train: 0.6113, Valid: 0.6416, Test: 0.6078\n",
            "Fold: 4, Epoch: 011, Train: 0.6030, Valid: 0.6165, Test: 0.6081\n",
            "Fold: 4, Epoch: 021, Train: 0.6004, Valid: 0.6090, Test: 0.6028\n",
            "Fold: 4, Epoch: 031, Train: 0.6119, Valid: 0.6216, Test: 0.6023\n",
            "Fold: 4, Epoch: 041, Train: 0.6035, Valid: 0.6115, Test: 0.6061\n",
            "Fold: 5, Epoch: 001, Train: 0.6141, Valid: 0.6165, Test: 0.6169\n",
            "Fold: 5, Epoch: 011, Train: 0.6180, Valid: 0.6341, Test: 0.6133\n",
            "Fold: 5, Epoch: 021, Train: 0.6183, Valid: 0.5990, Test: 0.6211\n",
            "Fold: 5, Epoch: 031, Train: 0.6183, Valid: 0.6040, Test: 0.6249\n",
            "Fold: 5, Epoch: 041, Train: 0.6283, Valid: 0.6591, Test: 0.6241\n",
            "Fold: 6, Epoch: 001, Train: 0.6244, Valid: 0.6366, Test: 0.6209\n",
            "Fold: 6, Epoch: 011, Train: 0.6286, Valid: 0.6416, Test: 0.6281\n",
            "Fold: 6, Epoch: 021, Train: 0.6364, Valid: 0.6717, Test: 0.6347\n",
            "Fold: 6, Epoch: 031, Train: 0.6372, Valid: 0.6717, Test: 0.6372\n",
            "Fold: 6, Epoch: 041, Train: 0.6383, Valid: 0.6817, Test: 0.6457\n",
            "Fold: 7, Epoch: 001, Train: 0.6414, Valid: 0.6441, Test: 0.6542\n",
            "Fold: 7, Epoch: 011, Train: 0.6542, Valid: 0.6466, Test: 0.6499\n",
            "Fold: 7, Epoch: 021, Train: 0.6525, Valid: 0.6466, Test: 0.6540\n",
            "Fold: 7, Epoch: 031, Train: 0.6592, Valid: 0.6391, Test: 0.6562\n",
            "Fold: 7, Epoch: 041, Train: 0.6626, Valid: 0.6416, Test: 0.6670\n",
            "Fold: 8, Epoch: 001, Train: 0.6615, Valid: 0.6466, Test: 0.6652\n",
            "Fold: 8, Epoch: 011, Train: 0.6709, Valid: 0.6541, Test: 0.6640\n",
            "Fold: 8, Epoch: 021, Train: 0.6590, Valid: 0.6241, Test: 0.6700\n",
            "Fold: 8, Epoch: 031, Train: 0.6762, Valid: 0.6416, Test: 0.6657\n",
            "Fold: 8, Epoch: 041, Train: 0.6812, Valid: 0.6817, Test: 0.6825\n",
            "Fold: 9, Epoch: 001, Train: 0.6727, Valid: 0.6960, Test: 0.6808\n",
            "Fold: 9, Epoch: 011, Train: 0.6813, Valid: 0.7085, Test: 0.6818\n",
            "Fold: 9, Epoch: 021, Train: 0.6825, Valid: 0.6985, Test: 0.6893\n",
            "Fold: 9, Epoch: 031, Train: 0.6841, Valid: 0.7161, Test: 0.6871\n",
            "Fold: 9, Epoch: 041, Train: 0.6836, Valid: 0.7136, Test: 0.6868\n",
            "Fold: 10, Epoch: 001, Train: 0.6953, Valid: 0.6985, Test: 0.6861\n",
            "Fold: 10, Epoch: 011, Train: 0.6850, Valid: 0.6884, Test: 0.6863\n",
            "Fold: 10, Epoch: 021, Train: 0.6875, Valid: 0.6960, Test: 0.6936\n",
            "Fold: 10, Epoch: 031, Train: 0.6967, Valid: 0.6734, Test: 0.6968\n",
            "Fold: 10, Epoch: 041, Train: 0.6975, Valid: 0.7010, Test: 0.6936\n",
            "\n",
            "Elapsed Time:  721.6981780529022\n"
          ]
        }
      ],
      "source": [
        "main('GCN', dataset_graph, test_graph, model_dir, result_dir, k_hop=1, k_fold=10, n_epo=50)"
      ],
      "id": "375bd1a0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a5157997",
        "outputId": "7146093f-d3a0-41d2-90a0-3236492924b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4455, Valid: 0.3810, Test: 0.4388\n",
            "Fold: 1, Epoch: 011, Train: 0.5319, Valid: 0.5213, Test: 0.5374\n",
            "Fold: 1, Epoch: 021, Train: 0.5458, Valid: 0.5890, Test: 0.5567\n",
            "Fold: 1, Epoch: 031, Train: 0.5712, Valid: 0.6216, Test: 0.5710\n",
            "Fold: 1, Epoch: 041, Train: 0.5815, Valid: 0.6341, Test: 0.5915\n",
            "Fold: 2, Epoch: 001, Train: 0.5965, Valid: 0.6015, Test: 0.5933\n",
            "Fold: 2, Epoch: 011, Train: 0.6007, Valid: 0.5915, Test: 0.6006\n",
            "Fold: 2, Epoch: 021, Train: 0.6016, Valid: 0.6341, Test: 0.6106\n",
            "Fold: 2, Epoch: 031, Train: 0.6119, Valid: 0.6165, Test: 0.6153\n",
            "Fold: 2, Epoch: 041, Train: 0.6172, Valid: 0.6291, Test: 0.6181\n",
            "Fold: 3, Epoch: 001, Train: 0.6342, Valid: 0.5965, Test: 0.6239\n",
            "Fold: 3, Epoch: 011, Train: 0.6372, Valid: 0.6140, Test: 0.6339\n",
            "Fold: 3, Epoch: 021, Train: 0.6486, Valid: 0.6190, Test: 0.6452\n",
            "Fold: 3, Epoch: 031, Train: 0.6598, Valid: 0.6040, Test: 0.6530\n",
            "Fold: 3, Epoch: 041, Train: 0.6645, Valid: 0.6040, Test: 0.6713\n",
            "Fold: 4, Epoch: 001, Train: 0.6718, Valid: 0.7018, Test: 0.6720\n",
            "Fold: 4, Epoch: 011, Train: 0.6893, Valid: 0.6742, Test: 0.6780\n",
            "Fold: 4, Epoch: 021, Train: 0.6860, Valid: 0.7193, Test: 0.6866\n",
            "Fold: 4, Epoch: 031, Train: 0.6835, Valid: 0.7043, Test: 0.6971\n",
            "Fold: 4, Epoch: 041, Train: 0.7058, Valid: 0.7143, Test: 0.6961\n",
            "Fold: 5, Epoch: 001, Train: 0.7113, Valid: 0.6867, Test: 0.7159\n",
            "Fold: 5, Epoch: 011, Train: 0.7191, Valid: 0.6967, Test: 0.7049\n",
            "Fold: 5, Epoch: 021, Train: 0.7094, Valid: 0.7043, Test: 0.7086\n",
            "Fold: 5, Epoch: 031, Train: 0.7177, Valid: 0.7043, Test: 0.7119\n",
            "Fold: 5, Epoch: 041, Train: 0.7267, Valid: 0.6917, Test: 0.7179\n",
            "Fold: 6, Epoch: 001, Train: 0.7244, Valid: 0.7143, Test: 0.7227\n",
            "Fold: 6, Epoch: 011, Train: 0.7334, Valid: 0.7193, Test: 0.7242\n",
            "Fold: 6, Epoch: 021, Train: 0.7283, Valid: 0.7343, Test: 0.7279\n",
            "Fold: 6, Epoch: 031, Train: 0.7342, Valid: 0.7143, Test: 0.7269\n",
            "Fold: 6, Epoch: 041, Train: 0.7331, Valid: 0.7268, Test: 0.7274\n",
            "Fold: 7, Epoch: 001, Train: 0.7272, Valid: 0.7368, Test: 0.7335\n",
            "Fold: 7, Epoch: 011, Train: 0.7359, Valid: 0.7368, Test: 0.7337\n",
            "Fold: 7, Epoch: 021, Train: 0.7347, Valid: 0.7619, Test: 0.7387\n",
            "Fold: 7, Epoch: 031, Train: 0.7403, Valid: 0.7318, Test: 0.7347\n",
            "Fold: 7, Epoch: 041, Train: 0.7381, Valid: 0.7569, Test: 0.7395\n",
            "Fold: 8, Epoch: 001, Train: 0.7462, Valid: 0.7619, Test: 0.7455\n",
            "Fold: 8, Epoch: 011, Train: 0.7423, Valid: 0.7519, Test: 0.7477\n",
            "Fold: 8, Epoch: 021, Train: 0.7381, Valid: 0.7794, Test: 0.7460\n",
            "Fold: 8, Epoch: 031, Train: 0.7384, Valid: 0.7393, Test: 0.7515\n",
            "Fold: 8, Epoch: 041, Train: 0.7428, Valid: 0.7243, Test: 0.7475\n",
            "Fold: 9, Epoch: 001, Train: 0.7474, Valid: 0.7487, Test: 0.7485\n",
            "Fold: 9, Epoch: 011, Train: 0.7504, Valid: 0.7412, Test: 0.7487\n",
            "Fold: 9, Epoch: 021, Train: 0.7526, Valid: 0.7412, Test: 0.7470\n",
            "Fold: 9, Epoch: 031, Train: 0.7529, Valid: 0.7462, Test: 0.7533\n",
            "Fold: 9, Epoch: 041, Train: 0.7476, Valid: 0.7513, Test: 0.7560\n",
            "Fold: 10, Epoch: 001, Train: 0.7574, Valid: 0.7261, Test: 0.7518\n",
            "Fold: 10, Epoch: 011, Train: 0.7568, Valid: 0.7236, Test: 0.7558\n",
            "Fold: 10, Epoch: 021, Train: 0.7568, Valid: 0.7337, Test: 0.7528\n",
            "Fold: 10, Epoch: 031, Train: 0.7602, Valid: 0.7136, Test: 0.7545\n",
            "Fold: 10, Epoch: 041, Train: 0.7554, Valid: 0.7261, Test: 0.7575\n",
            "\n",
            "Elapsed Time:  1161.9468047618866\n"
          ]
        }
      ],
      "source": [
        "main('GCN', dataset_graph, test_graph, model_dir, result_dir, k_hop=2, k_fold=10, n_epo=50)"
      ],
      "id": "a5157997"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4742f3ad",
        "outputId": "53b27f81-ce92-46af-dbe2-299bd33ff2bc",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4288, Valid: 0.4586, Test: 0.4341\n",
            "Fold: 1, Epoch: 011, Train: 0.5481, Valid: 0.5614, Test: 0.5481\n",
            "Fold: 1, Epoch: 021, Train: 0.5698, Valid: 0.5163, Test: 0.5634\n",
            "Fold: 1, Epoch: 031, Train: 0.5709, Valid: 0.5338, Test: 0.5695\n",
            "Fold: 1, Epoch: 041, Train: 0.5801, Valid: 0.5363, Test: 0.5795\n",
            "Fold: 2, Epoch: 001, Train: 0.5949, Valid: 0.6316, Test: 0.6006\n",
            "Fold: 2, Epoch: 011, Train: 0.6130, Valid: 0.6416, Test: 0.6158\n",
            "Fold: 2, Epoch: 021, Train: 0.6330, Valid: 0.6642, Test: 0.6316\n",
            "Fold: 2, Epoch: 031, Train: 0.6506, Valid: 0.6491, Test: 0.6632\n",
            "Fold: 2, Epoch: 041, Train: 0.6801, Valid: 0.6867, Test: 0.6773\n",
            "Fold: 3, Epoch: 001, Train: 0.6930, Valid: 0.6441, Test: 0.6958\n",
            "Fold: 3, Epoch: 011, Train: 0.7030, Valid: 0.6967, Test: 0.7079\n",
            "Fold: 3, Epoch: 021, Train: 0.7069, Valid: 0.6817, Test: 0.7081\n",
            "Fold: 3, Epoch: 031, Train: 0.7133, Valid: 0.7143, Test: 0.7202\n",
            "Fold: 3, Epoch: 041, Train: 0.7164, Valid: 0.7218, Test: 0.7239\n",
            "Fold: 4, Epoch: 001, Train: 0.7233, Valid: 0.7168, Test: 0.7254\n",
            "Fold: 4, Epoch: 011, Train: 0.7356, Valid: 0.7193, Test: 0.7309\n",
            "Fold: 4, Epoch: 021, Train: 0.7283, Valid: 0.7243, Test: 0.7365\n",
            "Fold: 4, Epoch: 031, Train: 0.7317, Valid: 0.7444, Test: 0.7360\n",
            "Fold: 4, Epoch: 041, Train: 0.7414, Valid: 0.7268, Test: 0.7329\n",
            "Fold: 5, Epoch: 001, Train: 0.7431, Valid: 0.7519, Test: 0.7360\n",
            "Fold: 5, Epoch: 011, Train: 0.7439, Valid: 0.7268, Test: 0.7365\n",
            "Fold: 5, Epoch: 021, Train: 0.7361, Valid: 0.7519, Test: 0.7425\n",
            "Fold: 5, Epoch: 031, Train: 0.7448, Valid: 0.7393, Test: 0.7397\n",
            "Fold: 5, Epoch: 041, Train: 0.7498, Valid: 0.7544, Test: 0.7482\n",
            "Fold: 6, Epoch: 001, Train: 0.7476, Valid: 0.7293, Test: 0.7452\n",
            "Fold: 6, Epoch: 011, Train: 0.7512, Valid: 0.7118, Test: 0.7530\n",
            "Fold: 6, Epoch: 021, Train: 0.7559, Valid: 0.7218, Test: 0.7460\n",
            "Fold: 6, Epoch: 031, Train: 0.7512, Valid: 0.7193, Test: 0.7608\n",
            "Fold: 6, Epoch: 041, Train: 0.7637, Valid: 0.7393, Test: 0.7593\n",
            "Fold: 7, Epoch: 001, Train: 0.7537, Valid: 0.7769, Test: 0.7568\n",
            "Fold: 7, Epoch: 011, Train: 0.7604, Valid: 0.7544, Test: 0.7580\n",
            "Fold: 7, Epoch: 021, Train: 0.7579, Valid: 0.7644, Test: 0.7590\n",
            "Fold: 7, Epoch: 031, Train: 0.7629, Valid: 0.7544, Test: 0.7598\n",
            "Fold: 7, Epoch: 041, Train: 0.7623, Valid: 0.7794, Test: 0.7608\n",
            "Fold: 8, Epoch: 001, Train: 0.7646, Valid: 0.7820, Test: 0.7615\n",
            "Fold: 8, Epoch: 011, Train: 0.7637, Valid: 0.7794, Test: 0.7671\n",
            "Fold: 8, Epoch: 021, Train: 0.7640, Valid: 0.7820, Test: 0.7683\n",
            "Fold: 8, Epoch: 031, Train: 0.7673, Valid: 0.7845, Test: 0.7640\n",
            "Fold: 8, Epoch: 041, Train: 0.7629, Valid: 0.7820, Test: 0.7671\n",
            "Fold: 9, Epoch: 001, Train: 0.7716, Valid: 0.7538, Test: 0.7748\n",
            "Fold: 9, Epoch: 011, Train: 0.7738, Valid: 0.7764, Test: 0.7706\n",
            "Fold: 9, Epoch: 021, Train: 0.7721, Valid: 0.7663, Test: 0.7708\n",
            "Fold: 9, Epoch: 031, Train: 0.7783, Valid: 0.7739, Test: 0.7758\n",
            "Fold: 9, Epoch: 041, Train: 0.7769, Valid: 0.7613, Test: 0.7718\n",
            "Fold: 10, Epoch: 001, Train: 0.7763, Valid: 0.7965, Test: 0.7726\n",
            "Fold: 10, Epoch: 011, Train: 0.7760, Valid: 0.7940, Test: 0.7741\n",
            "Fold: 10, Epoch: 021, Train: 0.7758, Valid: 0.7915, Test: 0.7763\n",
            "Fold: 10, Epoch: 031, Train: 0.7799, Valid: 0.7889, Test: 0.7783\n",
            "Fold: 10, Epoch: 041, Train: 0.7813, Valid: 0.7915, Test: 0.7823\n",
            "\n",
            "Elapsed Time:  1604.569087266922\n"
          ]
        }
      ],
      "source": [
        "main('GCN', dataset_graph, test_graph, model_dir, result_dir, k_hop=3, k_fold=10, n_epo=50)"
      ],
      "id": "4742f3ad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d068aff8",
        "outputId": "53988306-83a4-4527-d557-d69aabecb4fa",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4313, Valid: 0.4411, Test: 0.4328\n",
            "Fold: 1, Epoch: 011, Train: 0.5447, Valid: 0.5439, Test: 0.5429\n",
            "Fold: 1, Epoch: 021, Train: 0.5692, Valid: 0.5388, Test: 0.5657\n",
            "Fold: 1, Epoch: 031, Train: 0.5756, Valid: 0.5614, Test: 0.5787\n",
            "Fold: 1, Epoch: 041, Train: 0.5957, Valid: 0.5564, Test: 0.5945\n",
            "Fold: 2, Epoch: 001, Train: 0.6038, Valid: 0.5789, Test: 0.5960\n",
            "Fold: 2, Epoch: 011, Train: 0.6096, Valid: 0.5739, Test: 0.6056\n",
            "Fold: 2, Epoch: 021, Train: 0.6216, Valid: 0.5815, Test: 0.6284\n",
            "Fold: 2, Epoch: 031, Train: 0.6434, Valid: 0.6216, Test: 0.6459\n",
            "Fold: 2, Epoch: 041, Train: 0.6698, Valid: 0.6692, Test: 0.6647\n",
            "Fold: 3, Epoch: 001, Train: 0.6896, Valid: 0.7018, Test: 0.6978\n",
            "Fold: 3, Epoch: 011, Train: 0.7052, Valid: 0.7393, Test: 0.7006\n",
            "Fold: 3, Epoch: 021, Train: 0.7108, Valid: 0.7293, Test: 0.7011\n",
            "Fold: 3, Epoch: 031, Train: 0.7122, Valid: 0.7419, Test: 0.7197\n",
            "Fold: 3, Epoch: 041, Train: 0.7269, Valid: 0.7544, Test: 0.7252\n",
            "Fold: 4, Epoch: 001, Train: 0.7286, Valid: 0.7494, Test: 0.7277\n",
            "Fold: 4, Epoch: 011, Train: 0.7228, Valid: 0.7719, Test: 0.7360\n",
            "Fold: 4, Epoch: 021, Train: 0.7347, Valid: 0.7769, Test: 0.7405\n",
            "Fold: 4, Epoch: 031, Train: 0.7353, Valid: 0.7644, Test: 0.7372\n",
            "Fold: 4, Epoch: 041, Train: 0.7420, Valid: 0.7820, Test: 0.7400\n",
            "Fold: 5, Epoch: 001, Train: 0.7434, Valid: 0.7569, Test: 0.7475\n",
            "Fold: 5, Epoch: 011, Train: 0.7490, Valid: 0.7669, Test: 0.7477\n",
            "Fold: 5, Epoch: 021, Train: 0.7517, Valid: 0.7494, Test: 0.7565\n",
            "Fold: 5, Epoch: 031, Train: 0.7570, Valid: 0.7569, Test: 0.7603\n",
            "Fold: 5, Epoch: 041, Train: 0.7517, Valid: 0.7694, Test: 0.7565\n",
            "Fold: 6, Epoch: 001, Train: 0.7598, Valid: 0.7569, Test: 0.7540\n",
            "Fold: 6, Epoch: 011, Train: 0.7595, Valid: 0.7744, Test: 0.7618\n",
            "Fold: 6, Epoch: 021, Train: 0.7570, Valid: 0.7644, Test: 0.7573\n",
            "Fold: 6, Epoch: 031, Train: 0.7648, Valid: 0.7569, Test: 0.7655\n",
            "Fold: 6, Epoch: 041, Train: 0.7579, Valid: 0.7644, Test: 0.7663\n",
            "Fold: 7, Epoch: 001, Train: 0.7637, Valid: 0.7469, Test: 0.7691\n",
            "Fold: 7, Epoch: 011, Train: 0.7757, Valid: 0.7494, Test: 0.7706\n",
            "Fold: 7, Epoch: 021, Train: 0.7746, Valid: 0.7569, Test: 0.7736\n",
            "Fold: 7, Epoch: 031, Train: 0.7763, Valid: 0.7594, Test: 0.7698\n",
            "Fold: 7, Epoch: 041, Train: 0.7779, Valid: 0.7694, Test: 0.7746\n",
            "Fold: 8, Epoch: 001, Train: 0.7785, Valid: 0.7268, Test: 0.7731\n",
            "Fold: 8, Epoch: 011, Train: 0.7807, Valid: 0.7594, Test: 0.7791\n",
            "Fold: 8, Epoch: 021, Train: 0.7860, Valid: 0.7469, Test: 0.7773\n",
            "Fold: 8, Epoch: 031, Train: 0.7818, Valid: 0.7494, Test: 0.7751\n",
            "Fold: 8, Epoch: 041, Train: 0.7835, Valid: 0.7494, Test: 0.7818\n",
            "Fold: 9, Epoch: 001, Train: 0.7866, Valid: 0.7688, Test: 0.7844\n",
            "Fold: 9, Epoch: 011, Train: 0.7877, Valid: 0.7915, Test: 0.7818\n",
            "Fold: 9, Epoch: 021, Train: 0.7861, Valid: 0.7814, Test: 0.7884\n",
            "Fold: 9, Epoch: 031, Train: 0.7819, Valid: 0.7915, Test: 0.7846\n",
            "Fold: 9, Epoch: 041, Train: 0.7903, Valid: 0.7889, Test: 0.7846\n",
            "Fold: 10, Epoch: 001, Train: 0.7877, Valid: 0.7714, Test: 0.7916\n",
            "Fold: 10, Epoch: 011, Train: 0.7911, Valid: 0.8040, Test: 0.7891\n",
            "Fold: 10, Epoch: 021, Train: 0.7994, Valid: 0.7940, Test: 0.7974\n",
            "Fold: 10, Epoch: 031, Train: 0.7942, Valid: 0.7889, Test: 0.7924\n",
            "Fold: 10, Epoch: 041, Train: 0.7983, Valid: 0.8015, Test: 0.7954\n",
            "\n",
            "Elapsed Time:  2050.8925404548645\n"
          ]
        }
      ],
      "source": [
        "main('GCN', dataset_graph, test_graph, model_dir, result_dir, k_hop=4, k_fold=10, n_epo=50)"
      ],
      "id": "d068aff8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0XfpWn_Ei_rT",
        "outputId": "f70b6b9c-17a1-4694-a211-a41fedaf848c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4416, Valid: 0.4010, Test: 0.4358\n",
            "Fold: 1, Epoch: 011, Train: 0.5266, Valid: 0.5614, Test: 0.5318\n",
            "Fold: 1, Epoch: 021, Train: 0.5475, Valid: 0.5714, Test: 0.5559\n",
            "Fold: 1, Epoch: 031, Train: 0.5600, Valid: 0.5840, Test: 0.5589\n",
            "Fold: 1, Epoch: 041, Train: 0.5704, Valid: 0.6165, Test: 0.5762\n",
            "Fold: 2, Epoch: 001, Train: 0.5926, Valid: 0.5664, Test: 0.5850\n",
            "Fold: 2, Epoch: 011, Train: 0.6174, Valid: 0.5890, Test: 0.6116\n",
            "Fold: 2, Epoch: 021, Train: 0.6425, Valid: 0.6341, Test: 0.6487\n",
            "Fold: 2, Epoch: 031, Train: 0.6829, Valid: 0.6491, Test: 0.6871\n",
            "Fold: 2, Epoch: 041, Train: 0.7136, Valid: 0.6466, Test: 0.7034\n",
            "Fold: 3, Epoch: 001, Train: 0.7164, Valid: 0.6992, Test: 0.7141\n",
            "Fold: 3, Epoch: 011, Train: 0.7233, Valid: 0.6917, Test: 0.7199\n",
            "Fold: 3, Epoch: 021, Train: 0.7283, Valid: 0.7193, Test: 0.7292\n",
            "Fold: 3, Epoch: 031, Train: 0.7345, Valid: 0.7544, Test: 0.7335\n",
            "Fold: 3, Epoch: 041, Train: 0.7448, Valid: 0.7168, Test: 0.7437\n",
            "Fold: 4, Epoch: 001, Train: 0.7481, Valid: 0.7594, Test: 0.7427\n",
            "Fold: 4, Epoch: 011, Train: 0.7473, Valid: 0.7644, Test: 0.7490\n",
            "Fold: 4, Epoch: 021, Train: 0.7473, Valid: 0.7594, Test: 0.7528\n",
            "Fold: 4, Epoch: 031, Train: 0.7520, Valid: 0.7644, Test: 0.7535\n",
            "Fold: 4, Epoch: 041, Train: 0.7587, Valid: 0.7544, Test: 0.7563\n",
            "Fold: 5, Epoch: 001, Train: 0.7634, Valid: 0.7419, Test: 0.7663\n",
            "Fold: 5, Epoch: 011, Train: 0.7701, Valid: 0.7343, Test: 0.7638\n",
            "Fold: 5, Epoch: 021, Train: 0.7715, Valid: 0.7368, Test: 0.7671\n",
            "Fold: 5, Epoch: 031, Train: 0.7746, Valid: 0.7268, Test: 0.7733\n",
            "Fold: 5, Epoch: 041, Train: 0.7790, Valid: 0.7343, Test: 0.7753\n",
            "Fold: 6, Epoch: 001, Train: 0.7790, Valid: 0.7820, Test: 0.7796\n",
            "Fold: 6, Epoch: 011, Train: 0.7793, Valid: 0.7845, Test: 0.7776\n",
            "Fold: 6, Epoch: 021, Train: 0.7793, Valid: 0.8045, Test: 0.7726\n",
            "Fold: 6, Epoch: 031, Train: 0.7821, Valid: 0.7945, Test: 0.7808\n",
            "Fold: 6, Epoch: 041, Train: 0.7841, Valid: 0.7870, Test: 0.7801\n",
            "Fold: 7, Epoch: 001, Train: 0.7802, Valid: 0.8321, Test: 0.7836\n",
            "Fold: 7, Epoch: 011, Train: 0.7818, Valid: 0.8070, Test: 0.7881\n",
            "Fold: 7, Epoch: 021, Train: 0.7804, Valid: 0.8145, Test: 0.7861\n",
            "Fold: 7, Epoch: 031, Train: 0.7838, Valid: 0.8321, Test: 0.7894\n",
            "Fold: 7, Epoch: 041, Train: 0.7829, Valid: 0.8195, Test: 0.7884\n",
            "Fold: 8, Epoch: 001, Train: 0.7874, Valid: 0.7820, Test: 0.7911\n",
            "Fold: 8, Epoch: 011, Train: 0.7938, Valid: 0.7794, Test: 0.7866\n",
            "Fold: 8, Epoch: 021, Train: 0.7944, Valid: 0.7895, Test: 0.7936\n",
            "Fold: 8, Epoch: 031, Train: 0.7933, Valid: 0.7769, Test: 0.7911\n",
            "Fold: 8, Epoch: 041, Train: 0.7977, Valid: 0.7895, Test: 0.7961\n",
            "Fold: 9, Epoch: 001, Train: 0.8039, Valid: 0.7965, Test: 0.7951\n",
            "Fold: 9, Epoch: 011, Train: 0.7981, Valid: 0.7814, Test: 0.7986\n",
            "Fold: 9, Epoch: 021, Train: 0.8039, Valid: 0.8166, Test: 0.8024\n",
            "Fold: 9, Epoch: 031, Train: 0.7994, Valid: 0.7889, Test: 0.8029\n",
            "Fold: 9, Epoch: 041, Train: 0.7994, Valid: 0.8090, Test: 0.8007\n",
            "Fold: 10, Epoch: 001, Train: 0.8011, Valid: 0.7864, Test: 0.7994\n",
            "Fold: 10, Epoch: 011, Train: 0.8017, Valid: 0.7764, Test: 0.8019\n",
            "Fold: 10, Epoch: 021, Train: 0.8036, Valid: 0.7764, Test: 0.8037\n",
            "Fold: 10, Epoch: 031, Train: 0.8031, Valid: 0.7889, Test: 0.8042\n",
            "Fold: 10, Epoch: 041, Train: 0.8033, Valid: 0.8015, Test: 0.8037\n",
            "\n",
            "Elapsed Time:  2541.3555200099945\n"
          ]
        }
      ],
      "source": [
        "main('GCN', dataset_graph, test_graph, model_dir, result_dir, k_hop=5, k_fold=10, n_epo=50)"
      ],
      "id": "0XfpWn_Ei_rT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D8C75Y2Fi_mI",
        "outputId": "a1c40788-f078-43ad-d8d3-4e241645edb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4322, Valid: 0.4862, Test: 0.4368\n",
            "Fold: 1, Epoch: 011, Train: 0.5383, Valid: 0.5163, Test: 0.5411\n",
            "Fold: 1, Epoch: 021, Train: 0.5617, Valid: 0.4987, Test: 0.5559\n",
            "Fold: 1, Epoch: 031, Train: 0.5834, Valid: 0.5088, Test: 0.5792\n",
            "Fold: 1, Epoch: 041, Train: 0.6436, Valid: 0.6090, Test: 0.6422\n",
            "Fold: 2, Epoch: 001, Train: 0.6810, Valid: 0.7343, Test: 0.6933\n",
            "Fold: 2, Epoch: 011, Train: 0.7086, Valid: 0.7118, Test: 0.7109\n",
            "Fold: 2, Epoch: 021, Train: 0.7308, Valid: 0.7268, Test: 0.7262\n",
            "Fold: 2, Epoch: 031, Train: 0.7381, Valid: 0.7519, Test: 0.7365\n",
            "Fold: 2, Epoch: 041, Train: 0.7386, Valid: 0.7494, Test: 0.7500\n",
            "Fold: 3, Epoch: 001, Train: 0.7540, Valid: 0.7569, Test: 0.7538\n",
            "Fold: 3, Epoch: 011, Train: 0.7609, Valid: 0.7569, Test: 0.7568\n",
            "Fold: 3, Epoch: 021, Train: 0.7590, Valid: 0.7519, Test: 0.7563\n",
            "Fold: 3, Epoch: 031, Train: 0.7568, Valid: 0.7569, Test: 0.7628\n",
            "Fold: 3, Epoch: 041, Train: 0.7621, Valid: 0.7669, Test: 0.7620\n",
            "Fold: 4, Epoch: 001, Train: 0.7634, Valid: 0.7970, Test: 0.7696\n",
            "Fold: 4, Epoch: 011, Train: 0.7654, Valid: 0.8020, Test: 0.7655\n",
            "Fold: 4, Epoch: 021, Train: 0.7690, Valid: 0.7895, Test: 0.7638\n",
            "Fold: 4, Epoch: 031, Train: 0.7693, Valid: 0.7895, Test: 0.7668\n",
            "Fold: 4, Epoch: 041, Train: 0.7718, Valid: 0.7920, Test: 0.7681\n",
            "Fold: 5, Epoch: 001, Train: 0.7676, Valid: 0.7870, Test: 0.7736\n",
            "Fold: 5, Epoch: 011, Train: 0.7746, Valid: 0.7845, Test: 0.7763\n",
            "Fold: 5, Epoch: 021, Train: 0.7732, Valid: 0.7744, Test: 0.7816\n",
            "Fold: 5, Epoch: 031, Train: 0.7740, Valid: 0.7744, Test: 0.7788\n",
            "Fold: 5, Epoch: 041, Train: 0.7799, Valid: 0.7845, Test: 0.7816\n",
            "Fold: 6, Epoch: 001, Train: 0.7829, Valid: 0.7794, Test: 0.7798\n",
            "Fold: 6, Epoch: 011, Train: 0.7882, Valid: 0.7744, Test: 0.7831\n",
            "Fold: 6, Epoch: 021, Train: 0.7874, Valid: 0.7694, Test: 0.7846\n",
            "Fold: 6, Epoch: 031, Train: 0.7866, Valid: 0.7845, Test: 0.7881\n",
            "Fold: 6, Epoch: 041, Train: 0.7896, Valid: 0.7794, Test: 0.7874\n",
            "Fold: 7, Epoch: 001, Train: 0.7974, Valid: 0.7569, Test: 0.7856\n",
            "Fold: 7, Epoch: 011, Train: 0.7963, Valid: 0.7594, Test: 0.7919\n",
            "Fold: 7, Epoch: 021, Train: 0.7999, Valid: 0.7619, Test: 0.7911\n",
            "Fold: 7, Epoch: 031, Train: 0.7952, Valid: 0.7519, Test: 0.7954\n",
            "Fold: 7, Epoch: 041, Train: 0.8002, Valid: 0.7619, Test: 0.7946\n",
            "Fold: 8, Epoch: 001, Train: 0.7924, Valid: 0.7820, Test: 0.7956\n",
            "Fold: 8, Epoch: 011, Train: 0.7977, Valid: 0.7920, Test: 0.7994\n",
            "Fold: 8, Epoch: 021, Train: 0.7974, Valid: 0.7820, Test: 0.7964\n",
            "Fold: 8, Epoch: 031, Train: 0.7983, Valid: 0.7820, Test: 0.7989\n",
            "Fold: 8, Epoch: 041, Train: 0.7991, Valid: 0.7870, Test: 0.7991\n",
            "Fold: 9, Epoch: 001, Train: 0.7983, Valid: 0.7940, Test: 0.8004\n",
            "Fold: 9, Epoch: 011, Train: 0.8031, Valid: 0.8040, Test: 0.7996\n",
            "Fold: 9, Epoch: 021, Train: 0.8045, Valid: 0.8015, Test: 0.8019\n",
            "Fold: 9, Epoch: 031, Train: 0.8019, Valid: 0.7889, Test: 0.7999\n",
            "Fold: 9, Epoch: 041, Train: 0.8061, Valid: 0.7915, Test: 0.8022\n",
            "Fold: 10, Epoch: 001, Train: 0.8017, Valid: 0.8116, Test: 0.8059\n",
            "Fold: 10, Epoch: 011, Train: 0.8053, Valid: 0.8090, Test: 0.8022\n",
            "Fold: 10, Epoch: 021, Train: 0.8045, Valid: 0.8090, Test: 0.8072\n",
            "Fold: 10, Epoch: 031, Train: 0.8064, Valid: 0.8141, Test: 0.8062\n",
            "Fold: 10, Epoch: 041, Train: 0.8075, Valid: 0.8116, Test: 0.8074\n",
            "\n",
            "Elapsed Time:  3052.917834043503\n"
          ]
        }
      ],
      "source": [
        "main('GCN', dataset_graph, test_graph, model_dir, result_dir, k_hop=6, k_fold=10, n_epo=50)"
      ],
      "id": "D8C75Y2Fi_mI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KAy1WD8Hi_f-",
        "outputId": "eb944633-db23-4257-d2d6-9b79922c126e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1, Epoch: 001, Train: 0.4388, Valid: 0.4236, Test: 0.4376\n",
            "Fold: 1, Epoch: 011, Train: 0.5333, Valid: 0.5288, Test: 0.5401\n",
            "Fold: 1, Epoch: 021, Train: 0.5495, Valid: 0.5639, Test: 0.5539\n",
            "Fold: 1, Epoch: 031, Train: 0.5595, Valid: 0.5639, Test: 0.5557\n",
            "Fold: 1, Epoch: 041, Train: 0.5698, Valid: 0.5865, Test: 0.5765\n",
            "Fold: 2, Epoch: 001, Train: 0.6417, Valid: 0.6591, Test: 0.6499\n",
            "Fold: 2, Epoch: 011, Train: 0.7030, Valid: 0.6842, Test: 0.6923\n",
            "Fold: 2, Epoch: 021, Train: 0.7303, Valid: 0.7318, Test: 0.7302\n",
            "Fold: 2, Epoch: 031, Train: 0.7409, Valid: 0.7343, Test: 0.7447\n",
            "Fold: 2, Epoch: 041, Train: 0.7506, Valid: 0.7093, Test: 0.7477\n",
            "Fold: 3, Epoch: 001, Train: 0.7501, Valid: 0.8045, Test: 0.7503\n",
            "Fold: 3, Epoch: 011, Train: 0.7551, Valid: 0.8095, Test: 0.7540\n",
            "Fold: 3, Epoch: 021, Train: 0.7581, Valid: 0.8045, Test: 0.7613\n",
            "Fold: 3, Epoch: 031, Train: 0.7517, Valid: 0.8045, Test: 0.7548\n",
            "Fold: 3, Epoch: 041, Train: 0.7621, Valid: 0.8045, Test: 0.7691\n",
            "Fold: 4, Epoch: 001, Train: 0.7726, Valid: 0.7769, Test: 0.7711\n",
            "Fold: 4, Epoch: 011, Train: 0.7704, Valid: 0.7769, Test: 0.7751\n",
            "Fold: 4, Epoch: 021, Train: 0.7724, Valid: 0.7845, Test: 0.7716\n",
            "Fold: 4, Epoch: 031, Train: 0.7701, Valid: 0.7870, Test: 0.7736\n",
            "Fold: 4, Epoch: 041, Train: 0.7729, Valid: 0.7794, Test: 0.7773\n",
            "Fold: 5, Epoch: 001, Train: 0.7738, Valid: 0.7619, Test: 0.7771\n",
            "Fold: 5, Epoch: 011, Train: 0.7799, Valid: 0.7719, Test: 0.7781\n",
            "Fold: 5, Epoch: 021, Train: 0.7782, Valid: 0.7444, Test: 0.7776\n",
            "Fold: 5, Epoch: 031, Train: 0.7843, Valid: 0.7544, Test: 0.7831\n",
            "Fold: 5, Epoch: 041, Train: 0.7816, Valid: 0.7719, Test: 0.7849\n",
            "Fold: 6, Epoch: 001, Train: 0.7804, Valid: 0.7945, Test: 0.7871\n"
          ]
        }
      ],
      "source": [
        "main('GCN', dataset_graph, test_graph, model_dir, result_dir, k_hop=7, k_fold=10, n_epo=50)"
      ],
      "id": "KAy1WD8Hi_f-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyVPWDZ8i_Yu"
      },
      "outputs": [],
      "source": [
        "main('GCN', dataset_graph, test_graph, model_dir, result_dir, k_hop=8, k_fold=10, n_epo=50)"
      ],
      "id": "QyVPWDZ8i_Yu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3R4JAiyMi_NH"
      },
      "outputs": [],
      "source": [
        "main('GCN', dataset_graph, test_graph, model_dir, result_dir, k_hop=9, k_fold=10, n_epo=50)"
      ],
      "id": "3R4JAiyMi_NH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga5b3TESi-NG"
      },
      "outputs": [],
      "source": [
        "main('GCN', dataset_graph, test_graph, model_dir, result_dir, k_hop=10, k_fold=10, n_epo=50)"
      ],
      "id": "ga5b3TESi-NG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "958d752c"
      },
      "source": [
        "## DIFF Training with k = 1, 2, 3, 4"
      ],
      "id": "958d752c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6fd75d3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "main('DIFF', dataset_graph, test_graph, model_dir, result_dir, k_hop=1, k_fold=10, n_epo=50)"
      ],
      "id": "a6fd75d3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f20b458",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "main('DIFF', dataset_graph, test_graph, model_dir, result_dir, k_hop=2, k_fold=10, n_epo=50)"
      ],
      "id": "2f20b458"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "950ee4d7"
      },
      "outputs": [],
      "source": [
        "main('DIFF', dataset_graph, test_graph, model_dir, result_dir, k_hop=3, k_fold=10, n_epo=50)"
      ],
      "id": "950ee4d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a687c29"
      },
      "outputs": [],
      "source": [
        "main('DIFF', dataset_graph, test_graph, model_dir, result_dir, k_hop=4, k_fold=10, n_epo=50)"
      ],
      "id": "3a687c29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ChLi27v43go"
      },
      "source": [
        "## CNN Training"
      ],
      "id": "8ChLi27v43go"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fb8931e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "main('CNN', dataset_image, test_dataset_img, model_dir, result_dir, n_epo=50)"
      ],
      "id": "4fb8931e"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}